var documenterSearchIndex = {"docs":
[{"location":"home.html#Equation-Learning","page":"Home","title":"Equation Learning","text":"","category":"section"},{"location":"home.html","page":"Home","title":"Home","text":"Click here to go back to the repository.","category":"page"},{"location":"home.html","page":"Home","title":"Home","text":"","category":"page"},{"location":"home.html","page":"Home","title":"Home","text":"This package allows for the learning of mechanisms T(t mathbfalpha), D(u mathbfbeta), and R(u mathbfgamma) for  delay, diffusion, and reaction model, for some cell data u and points (x t), assuming that u satisfies the model","category":"page"},{"location":"home.html","page":"Home","title":"Home","text":"fracpartial upartial t = T(t mathbfalpha)leftfracpartialpartial xleft(D(u mathbfbeta)fracpartial upartial xright) + R(u mathbfgamma)right","category":"page"},{"location":"home.html","page":"Home","title":"Home","text":"The package fits a Gaussian process to the data u at these points (x t) and uses it to draw samples from, allowing for multiple estimates of the parameters mathbfalpha, mathbfbeta, and mathbfgamma to be obtained, thus providing uncertainty quantification for these learned mechanisms. See our paper ... for more details. The main function exported by this package is bootstrap_gp which actual fits a given model with uncertainty quantification.","category":"page"},{"location":"tut.html#Tutorial","page":"Tutorial","title":"Tutorial","text":"","category":"section"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"Here we describe how the methods in this package can be used. We illustrate this on the 12,000 cells per well dataset from Jin et al. (2016). We only show how we could fit a delayed Fisher-Kolmogorov model. Instructions for fitting, for example, a model with the basis function approach can be found by looking at the corresponding code from our paper as described here. We start with the following:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"# Packages\nusing EquationLearning      # Load our actual package \nusing DelimitedFiles        # For loading the density data of Jin et al. (2016).\nusing DataFrames            # For conveniently representing the data\nusing LinearAlgebra         # For setting number of threads to prevent StackOverflowError\n# Plots and setup\ncolors = [:black, :blue, :red, :magenta, :green]\nLinearAlgebra.BLAS.set_num_threads(1)\n# Read in the data \nfunction prepare_data(filename) # https://discourse.julialang.org/t/failed-to-precompile-csv-due-to-load-error/70146/2\n    data, header = readdlm(filename, ',', header=true)\n    df = DataFrame(data, vec(header))\n    df_new = identity.(df)\n    return df_new\nend\nassay_data = Vector{DataFrame}([])\nx_scale = 1000.0 # μm ↦ mm \nt_scale = 24.0   # hr ↦ day \nfor i = 1:6\n    file_name = string(\"data/CellDensity_\", 10 + 2 * (i - 1), \".csv\") # This assumes that you are in the VandenHeuvel2022_Paper code folder of our repository. If the data is hosted somewhere else, simply change this line to locate the correct directory.\n    dat = prepare_data(file_name)\n    dat.Position = convert.(Float64, dat.Position)\n    dat.Time = convert.(Float64, dat.Time)\n    dat.Position ./= x_scale\n    dat.Dens1 .*= x_scale^2\n    dat.Dens2 .*= x_scale^2\n    dat.Dens3 .*= x_scale^2\n    dat.AvgDens .*= x_scale^2\n    dat.Time ./= t_scale\n    push!(assay_data, dat)\nend\nK = 1.7e-3 * x_scale^2 # Cell carrying capacity as estimated from Jin et al. (2016).\ndat = assay_data[2] # The data we will be using in this tutorial","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"For this data we also need to extract x, t, u, and the values to use for the PDEs:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"x = repeat(dat.Position, outer=3)\nt = repeat(dat.Time, outer=3)\nu = vcat(dat.Dens1, dat.Dens2, dat.Dens3)\nx_pde = dat.Position\nt_pde = dat.Time\nu_pde = dat.AvgDens","category":"page"},{"location":"tut.html#PDE-parameters","page":"Tutorial","title":"PDE parameters","text":"","category":"section"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"The first step is to define the PDE setup. Our function needs a PDE_Setup struct from the following function:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"struct PDE_Setup\n    meshPoints::AbstractVector     \n    LHS::Vector{Float64}\n    RHS::Vector{Float64}\n    finalTime::Float64\n    δt::AbstractVector\n    alg\nend","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"The field meshPoints gives the grid points for the discretised PDE, LHS gives the coefficients in the boundary condition a_0u(a t) - b_0partial u(a t)partial x = c_0, RHS gives the coefficients in the boundary condition a_1u(b t) + b_1partial u(b t)partial x = c_1, finalTime gives the time that the solution is solved up to, δt gives the vector of points to return the solution at, and alg gives the algorithm to use for solving the system of ODEs arising from the discretised PDE. We use the following:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"δt = LinRange(0.0, 48.0 / t_scale, 5)\nfinalTime = 48.0 / t_scale\nN = 500\nLHS = [0.0, 1.0, 0.0]\nRHS = [0.0, -1.0, 0.0]\nalg = Tsit5()\nmeshPoints = LinRange(75.0 / x_scale, 1875.0 / x_scale, N)\npde_setup = PDE_Setup(meshPoints, LHS, RHS, finalTime, δt, alg)","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"Note that these boundary conditions LHS and RHS correspond to no flux boundary conditions. For PDE_Setup we also provide a constructor with defaults:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"meshPoints = LinRange(extrema(x)..., 500).\nLHS = [0.0, 1.0, 0.0].\nRHS = [0.0, -1.0, 0.0].\nfinalTime = maximum(t).\nδt = finalTime / 4.0.\nalg = nothing.","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"See the manual for more details.","category":"page"},{"location":"tut.html#Bootstrapping-parameters","page":"Tutorial","title":"Bootstrapping parameters","text":"","category":"section"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"The next step is to define the parameters for bootstrapping. The following struct is used for these parameters:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"struct Bootstrap_Setup\n    bootₓ::AbstractVector\n    bootₜ::AbstractVector\n    B::Int\n    τ::Tuple{Float64,Float64}\n    Optim_Restarts::Int\n    constrained::Bool\n    obj_scale_GLS::Function\n    obj_scale_PDE::Function\n    init_weight::Float64\n    show_losses::Bool\nend","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"The bootₓ field gives the spatial grid for bootstrapping, bootₜ the spatial grid for bootstrapping, B the number of bootstrap iterations, τ the two threshold parameters for data thresholding, Optim_Restarts the number of the times the optimiser should be restarted, constrained an indicator for whether the optimisation problem should be constrained, obj_scale_GLS the transformation to apply to the GLS loss function, obj_scale_PDE the transformation to apply to the PDE loss function, init_weight the weighting to apply in the GLS loss function to the data at t = 0, and show_losses an indicator for whether the losses should be printed to the REPL at each stage of the optimiser.","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"For this problem we will use n = m = 50 points in space and time for the bootstrapping grid, and 100 bootstrap iterations with no optimiser restarts. We do not constrain the parameter estimates. To put the loss functions on roughly the same scale we will apply a log transformation to each individual loss function. We weight the data at t=0 by a factor of 10, and we do not show the losses in the REPL. We set this up as follows:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"nₓ = 50\nnₜ = 50\nbootₓ = LinRange(75.0 / x_scale, 1875.0 / x_scale, nₓ)\nbootₜ = LinRange(0.0, 48.0 / t_scale, nₜ)\nB = 100\nτ = (0.0, 0.0)\nOptim_Restarts = 1\nconstrained = false\nobj_scale_GLS = log\nobj_scale_PDE = log\ninit_weight = 10.0\nshow_losses = false\nbootstrap_setup = Bootstrap_Setup(bootₓ, bootₜ, B, τ, Optim_Restarts, constrained, obj_scale_GLS, obj_scale_PDE, init_weight, show_losses)","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"This struct also have a constructor, for which the defaults are:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"bootₓ = LinRange(extrema(x)..., 80)\nbootₜ = LinRange(extrema(t)..., 80).\nB = 100.\nτ = (0.0, 0.0).\nOptim_Restarts = 5.\nconstrained = false.\nobj_scale_GLS = x -> x.\nobj_scale_PDE = x -> x.\ninit_weight = 10.0.\nshow_losses = false.","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"See the manual for more details.","category":"page"},{"location":"tut.html#Gaussian-process-parameters","page":"Tutorial","title":"Gaussian process parameters","text":"","category":"section"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"The Gaussian process parameters are setup in the GP_Setup struct, defined as:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"struct GP_Setup\n    ℓₓ::Vector{Float64}\n    ℓₜ::Vector{Float64}\n    σ::Vector{Float64}\n    σₙ::Vector{Float64}\n    GP_Restarts::Int\n    μ::Union{Missing,Vector{Float64}}\n    L::Union{Missing,LowerTriangular{Float64}}\n    nugget::Float64\n    gp::Union{Missing,GPBase}\nend","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"The ℓₓ field gives a vector defining the interval to sample the spatial length scales between, ℓₜ the vector defining the interval to sample the spatial length scales between, σ the standard deviation of the noise-free data, σₙ the standard deviation of the noise, GP_Restarts the number of time to refit the Gaussian process to improve the hyperparameter estimates, μ the mean vector of the Gaussian process and derivatives (or missing if it should be computed in bootstrap_gp itself), L the Cholesky vector of the Gaussian process and derivatives (or missing if it should be computed in bootstrap_gp itself), nugget the nugget term for regularising the covariance matrix such that it is symmetric positive definite, and gp the fitted Gaussian process for just the cell density (or missing if it should be computed in bootstrap_gp itself).","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"Since we scale the data to be between 0 and 1 when fitting the Gaussian process, we pick our length scales to be between 0 and 1; these length scales must be defined on a log scale due to how they are defined in GaussianProcesses.jl. The values for the standard deviations are less clear and so we will choose it to be small, and also base it on the standard deviation of the observed data. A reasonably small nugget value needs to be used. Moreover, we can use many optimiser restarts since the Gaussian processes are not too expensive to fit. This leads to the following parameters:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"ℓₓ = log.([1e-6, 1.0])\nℓₜ = log.([1e-6, 1.0])\nnugget = 1e-5\nGP_Restarts = 250\nσ = log.([1e-6, 7std(u)])\nσₙ = log.([1e-6, 7std(u)])\ngp, μ, L = EquationLearning.precompute_gp_mean(x, t, u, ℓₓ, ℓₜ, σ, σₙ, nugget, GP_Restarts, bootstrap_setup)\ngp_setup = GP_Setup(u; ℓₓ, ℓₜ, σ, σₙ, GP_Restarts, μ, L, nugget, gp)","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"This struct GP_Setup also has a constructor with the following defaults:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"ℓₓ = log.([1e-6, 1.0]).\nℓₜ = log.([1e-6, 1.0]).\nσ = log.([1e-6, 7std(u)]).\nσₙ = log.([1e-6, 7std(u)]).\nGP_Restarts = 50.\nμ = missing.\nL = missing.\nnugget = 1e-4.\ngp = missing.","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"See the manual for more details.","category":"page"},{"location":"tut.html#Defining-the-functions","page":"Tutorial","title":"Defining the functions","text":"","category":"section"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"Now we want to define the functions and the corresponding parameter scales. Remember that the model we want to fit takes the form","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"fracpartial upartial t = T(t mathbfalpha)leftleft(D(u mathbfbeta)fracpartial upartial xright) + R(u mathbfgamma)right","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"where ","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"T(t mathbfalpha) = frac11+exp(-alpha_1-alpha_2t) quad D(u mathbfalpha) = beta_1 quad R(u mathbfgamma) = gamma_1uleft(1-fracuKright)","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"The function bootstrap_gp assumes that T, D, and R are given as functions of (t mathbfalpha mathbfp), (u mathbfbeta mathbfp), and (u mathbfgamma mathbfp), respectively. This vector mathbfp gives a vector of known parameters for each of the functions, and is used to allow for type stability in the functions. In particular, it would be wrong to define the reaction function as","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"R = (u, γ, p) -> γ[1] * u * (1.0 - u / K)","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"since K is in the scope of the main Julia REPL rather than the function itself, potentially leading to problems with type stability and making the function significantly slower. With this in mind, we define our functions as follows:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"T = (t, α, p) -> 1.0 / (1.0 + exp(-α[1] * p[1] - α[2] * p[2] * t))\nD = (u, β, p) -> β[1] * p[1]\nR = (u, γ, p) -> γ[1] * p[2] * u * (1.0 - u / p[1])\nD′ = (u, β, p) -> 0.0\nR′ = (u, γ, p) -> γ[1] * p[2] - 2.0 * γ[1] * p[2] * u / p[1]","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"The derivative for the reaction term is not currently used, but in the future it may be used and we thus include it as a necessary term in bootstrap_gp, hence its presence here. In these functions we give each parameter a corresponding value in the vector mathbfp, which we can use to put the parameters on the same scale. To now think about defining mathbfp, we could set the parameter scales to be 1 and fit a small number of models, as described in great detail in the first simulation study of our paper. We will instead provide a way that should typically good enough (that is only specific to this dataset since there already exist papers that study this data). In Table 1 of Jin et al. (2016), the values for beta_1 and gamma_1 are given as 250 pm 140 and 0044 pm 0002, respectively, in units of mutextrmm^2textrmh^-1 and textrmh^-1, respectively. The delay term should not, affect these estimates so significantly, although we do not expect to get these exact same parameter values, so we should not scale the parameters with exactly these values. Similarly, although they consider a different form of the model, Lagergren et al. (2020) present the same delay model for this dataset, finding alpha_1 = -33013 and alpha_2 = 02293 (textrmhr^-1). Based on these estimates, and with some other configuring with these estimates (after running the model for a small number of models to further improve these estimates in a significantly faster time than if we simply started with unit parameter scales), we define the following parameters:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"T_params = [-1.6, 0.2 * t_scale]\nD_params = [160.0 * t_scale / x_scale^2]\nR_params = [K, 0.057 * t_scale]","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"Note that we multiply by t_scale and x_scale so that we shift the parameters into the correct units.","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"The remaining required arguments in bootstrap_gp are the bounds on parameters, and placeholder vectors for the number of parameters to estimate for each mechanism. For these latter arguments, we simply define:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"α₀ = [1.0, 1.0]\nβ₀ = [1.0]\nγ₀ = [1.0]","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"The values do not matter, they just have to have the same values. For the parameter bounds, these do not matter since we will not be doing any optimiser restarts. (These bounds are not constraints on the parameters since we have constrained = false; in this case they simply define the hypercube for the Latin hypercube sampler to use for sampling parameter estimates.) We still have to provide both in this case. When we use a single optimiser restart, the initial value used in the optimiser is the middle of the given parameter bounds. Since we scale the parameters to all (hopefully) be mathcal O(1), we start each parameter at 1:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"lowers = [0.99, 0.99, 0.99, 0.99]\nuppers = [1.01, 1.01, 1.01, 1.01]","category":"page"},{"location":"tut.html#Fitting-the-model","page":"Tutorial","title":"Fitting the model","text":"","category":"section"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"We now fit the model. (Since we are not going to be performing any model comparisons in this tutorial, we do not provide a zvals argument; see how we use this argument for model comparison in VandenHeuvel2022PaperCode/papercode.jl by first defining a zvals vector and then using zvals = zvals in bootstrap_gp. These zvals are also provided in the struct for the final results, so we could instead not provide them and simply reuse the zvals from the first model.) We call the function as:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"optim_setup = Optim.Options(iterations=10, f_reltol=1e-4, x_reltol=1e-4, g_reltol=1e-4, outer_f_reltol=1e-4, outer_x_reltol=1e-4, outer_g_reltol=1e-4)\nbgp = bootstrap_gp(x, t, u, T, D, D′, R, R′, α₀, β₀, γ₀, lowers, uppers; gp_setup, bootstrap_setup, optim_setup, pde_setup, D_params, R_params, T_params, verbose=false)","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"We also include some optimisation options in this call. The verbose=false argument is used to prevent any spam from the differential equations solver in the REPL in case the parameters enter a region where all the solutions become unstable (which it will eventually exit out of and give reasonable parameter estimates, but this issue can occasionally happen for certain models). Other arguments for the differential equations solver, i.e. for the solve function from DifferentialEquations.jl, can be similarly provided by keyword.","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"This result bgp is a BootResults struct, defined as follows:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"struct BootResults\n    delayBases::Array{Float64}\n    diffusionBases::Array{Float64}\n    reactionBases::Array{Float64}\n    gp::GPBase\n    zvals::Array{Float64}\n    Xₛ::Array{Float64}\n    Xₛⁿ::Array{Float64}\n    bootₓ::Vector{Float64}\n    bootₜ::Vector{Float64}\n    T::Function\n    D::Function\n    D′::Function\n    R::Function\n    R′::Function\n    D_params\n    R_params\n    T_params\n    μ::Vector{Float64}\n    L::LowerTriangular{Float64}\n    gp_setup::GP_Setup\n    bootstrap_setup::Bootstrap_Setup\n    pde_setup::PDE_Setup\nend","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"The meaning for each field is self-explanatory. We also define a similar struct for computing the PDE solutions, plots, and AICs:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"struct AllResults\n    pde_solutions::Array{Float64}\n    AIC::Vector{Float64}\n    bgp::Union{BootResults,BasisBootResults}\n    delayCIs\n    diffusionCIs\n    reactionCIs\n    delay_density::Figure\n    diffusion_density::Figure\n    reaction_density::Figure\n    delay_curve::Figure\n    diffusion_curve::Figure\n    reaction_curve::Figure\n    pde_plot::Figure\n    pde_error::Vector{Float64}\nend","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"We would typically use the constructor AllResults(x_pde, t_pde, u_pde, bgp) for constructing this struct. Since we have scaled the data, we also want to make use of additional keyword arguments to put the data back on the original scale. We thus create the AllResults struct for this data as:","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"delay_scales = [T_params[1], T_params[2] / t_scale]\ndiffusion_scales = D_params[1] * x_scale^2 / t_scale\nreaction_scales = R_params[2] / t_scale\nres = AllResults(x_pde, t_pde, u_bgp, bgp; delay_scales, diffusion_scales, reaction_scales, x_scale, t_scale, correct = true)","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"The correct = true keyword argument is used so that a small sample size correction is used for the computed AICs.","category":"page"},{"location":"tut.html#Looking-at-the-results","page":"Tutorial","title":"Looking at the results","text":"","category":"section"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"To finish the tutorial, we discuss how we could look at the results. The plots are all stored in this res variable we computed above. We do not show the plots here, but we would just look through the plots by writing in the REPL (the results may vary if you are running code alongside this tutorial due to the random number generation):","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"julia> res\n\nBootstrapping results\n\nNumber of bootstrap samples: 100\nPDE Error: (10.1, 14.5)\nAIC: (1.56e+03, 1.68e+03)\n\nα[1]: (-3.09, -0.854)\nα[2]: (0.133, 0.307)\nβ[1]: (117, 222)\nγ[1]: (0.0548, 0.0615)\n\n\njulia> res.pde_error\n2-element Vector{Float64}:\n 10.104350220097093\n 14.546789846145\n\njulia> res.delay_density\n\njulia> res.delay_curve\n\njulia> res.diffusion_density\n\njulia> res.diffusion_curve\n\njulia> res.reaction_density\n\njulia> res.reaction_curve","category":"page"},{"location":"tut.html","page":"Tutorial","title":"Tutorial","text":"These plots may not always be what is desired by the user. Customising these plots based on the bgp results may take some work, and ways that we could for example plot all these plots in the same figure (as we do in the paper), are given in the plotting functions in VandenHeuvel2022PaperCode/papercode.jl.","category":"page"},{"location":"paper.html#VandenHeuvel-et-al.-(2022)","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"","category":"section"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"This section briefly discusses our paper, and steps for reproducing the figures in the paper. The paper  can be found here ..., and the abstract of the paper is:","category":"page"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"Parameter estimation for biological processes is often a difficult problem and depends significantly on the quality and quantity of avaiable data. We introduce a new framework which utilises Gaussian processes to discover the mechanisms underlying delay, diffusion, and reaction in a cell invasion process. Gaussian processes are leveraged with bootstrapping to provide uncertainty quantification for the mechanisms that drive the invasion process. Our framework is efficient and easily parallelisable, and can be applied to other problems. We illustrate our methods on a scratch assay experiment, demonstrating how simply we can explore different functional forms and develop and test hypotheses about underlying mechanisms, such as whether delay is present in the cell invasion process.","category":"page"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"The scratch assay data from Jin et al. (2016) can be found in this GitHub repository in VandenHeuvel2022_PaperCode/data.","category":"page"},{"location":"paper.html#Paper-results","page":"VandenHeuvel et al. (2022)","title":"Paper results","text":"","category":"section"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"The main body of the paper is produced using the code in VandenHeuvel2022PaperCode/papercode.jl. Below, we list the sections that this script is broken into, along with descriptions of these sections:","category":"page"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"Load the required packages\nHere we simply load all the necessary packages.\nSet some global parameters \n(Note that we also have a section called this in 7. below.) This section defines some parameters for plotting that are used in most of the sections. We also write:\njulia  LinearAlgebra.BLAS.set_num_threads(1)\nThis setting was used to remove issues relating to A \\ b giving StackOverflowError. See, for example, #43301 or #43242.\nRead in the data from Jin et al. (2016)\nHere we read in the data from Jin et al. (2016), scaling the data by hat x = 1000 and hat t = 24.\nFigure X: Plotting the density data from Jin et al. (2016)\nThis code plots the data from Jin et al. (2016) and also plots a curve through the average of the experimental replicates at each point in sspace and time.\nFigure X: Plotting the Gaussian processes fit to the data from Jin et al. (2016)\nThis section plots the Gaussian processes over the data from Jin et al. (2016), These Gaussian processes are fit using GaussianProcesses.jl.\nFigure X: Plotting the space-time diagram for the Gaussian process\nThis section plots the same Gaussian processes, but now plots them on the (x t) place, colouring the points by the mean of the Gaussian process posterior at each point (x t).\nSet some global parameters \nThis section now defines the global parameters for the bootstrapping. The parameters for the PDE are defined first, and then the parameters for bootstrapping. We also remove the left-most points from the data from Jin et al. (2016) here.\nModel fits\nThis section contains the actual code that gives the figures in the paper. There are five functions that we define first:\nmodel_fits: This function fits, for a given dataset, a Fisher-Kolmogorov model (with and without delay), a Porous-Fisher model (with and without delay), and a delayed generalised Porous-FKPP model.\nplot_fisher_kolmogorov_delay: This function plots the results from a delayed Fisher-Kolmogorov model.\nplot_generalised_fkpp_delay: This function plots the results from a delayed generalised Porous-FKPP model.\nplot_pde_soln!: This function adds, to an existing figure, an axis for the PDE solutions for a given dataset.\nplot_pde_soln: For the six datasets, this function plots all of the PDE solutions from each dataset on the same figure.\nAfter these functions are defined, we define parameters that scale each parameter for each function such that the scaled parameters that we have to estimate are all mathcal O(1). We based these parameter scales on the results from Jin et al. (2016) and Lagergren et al. (2020), or adjusted further based on issues we observed when fitting models. We then fit all the models, which takes a reasonably long time to complete. We then make all the plots.","category":"page"},{"location":"paper.html#Simulation-studies","page":"VandenHeuvel et al. (2022)","title":"Simulation studies","text":"","category":"section"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"We also present several simulation studies in the paper, all of which are given in VandenHeuvel2022PaperCode/simulationstudies.jl.","category":"page"},{"location":"paper.html#Simulation-study-I:-Fisher-Kolmogorov-Model,-10,000-cells-per-well","page":"VandenHeuvel et al. (2022)","title":"Simulation study I: Fisher-Kolmogorov Model, 10,000 cells per well","text":"","category":"section"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"In this study we fit some models to data simulated from the Fisher-Kolmogorov model","category":"page"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"fracpartial upartial t = beta_1fracpartial^2upartial x^2 + gamma_1uleft(1-fracuKright)","category":"page"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"Running all this code will produce the figures in the corresponding section of our paper.","category":"page"},{"location":"paper.html#Simulation-study-I:-Fisher-Kolmogorov-Model,-10,000-cells-per-well-2","page":"VandenHeuvel et al. (2022)","title":"Simulation study I: Fisher-Kolmogorov Model, 10,000 cells per well","text":"","category":"section"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"In this study we fit some models to data simulated from the Fisher-Kolmogorov model","category":"page"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"fracpartial upartial t = beta_1fracpartial^2upartial x^2 + gamma_1uleft(1-fracuKright)","category":"page"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"Running all this code will produce the figures in the corresponding section of our paper.","category":"page"},{"location":"paper.html#Simulation-study-II:-Fisher-Kolmogorov-Model-with-delay,-10,000-cells-per-well","page":"VandenHeuvel et al. (2022)","title":"Simulation study II: Fisher-Kolmogorov Model with delay, 10,000 cells per well","text":"","category":"section"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"In this study we fit some models to data simulated from the delayed Fisher-Kolmogorov model","category":"page"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"fracpartial upartial t = frac11+exp(-alpha_1-alpha_2t)leftbeta_1fracpartial^2upartial x^2 + gamma_1uleft(1-fracuKright)right","category":"page"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"Running all this code will produce the figures in the corresponding section of our paper.","category":"page"},{"location":"paper.html#Simulation-study-III:-Fisher-Kolmogorov-model,-10,000-cells-per-well,-basis-function-approach","page":"VandenHeuvel et al. (2022)","title":"Simulation study III: Fisher Kolmogorov model, 10,000 cells per well, basis function approach","text":"","category":"section"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"This study fits the same model as in study I, but using the basis function approach. Running all this code will produce the figures in the corresponding section of our paper.","category":"page"},{"location":"paper.html#Simulation-study-IV:-Data-thresholding-on-the-Fisher-Kolmogorov-model-of-Study-I","page":"VandenHeuvel et al. (2022)","title":"Simulation study IV: Data thresholding on the Fisher-Kolmogorov model of Study I","text":"","category":"section"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"This study considers the effects of data thresholding on the model in the first study. This study is done by simply looping over many tolerance values. Running all this code will produce the figures in the corresponding section of our paper.","category":"page"},{"location":"paper.html#Simulation-study-V:-Data-thresholding-on-the-Fisher-Kolmogorov-model-of-Study-II","page":"VandenHeuvel et al. (2022)","title":"Simulation study V: Data thresholding on the Fisher-Kolmogorov model of Study II","text":"","category":"section"},{"location":"paper.html","page":"VandenHeuvel et al. (2022)","title":"VandenHeuvel et al. (2022)","text":"This study considers the effects of data thresholding on the model in the second study. This study is done by simply looping over many tolerance values. Running all this code will produce the figures in the corresponding section of our paper.","category":"page"},{"location":"index.html#Index","page":"Index","title":"Index","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"All the docstrings in this package are listed below. We separate the docstrings by file.","category":"page"},{"location":"index.html#basis_bootstrapping.jl","page":"Index","title":"basis_bootstrapping.jl","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"Modules = [EquationLearning]\nPages = [\"basis_bootstrapping.jl\"]","category":"page"},{"location":"index.html#EquationLearning.basis_bootstrap_gp-Union{Tuple{T1}, Tuple{T1, T1, T1, Vector{Function}, Vector{Function}, Vector{Function}, Vector{Function}}} where T1<:(AbstractVector)","page":"Index","title":"EquationLearning.basis_bootstrap_gp","text":"basis_bootstrap_gp(x::T1, t::T1, u::T1,\n    D::Vector{Function}, D′::Vector{Function}, R::Vector{Function}, R′::Vector{Function};\n    gp_setup::GP_Setup = GP_Setup(u),\n    bootstrap_setup::Bootstrap_Setup = Bootstrap_Setup(x, t, u),\n    optim_setup::Optim.Options = Optim.Options(),\n    pde_setup::PDE_Setup = PDE_Setup(x),\n    D_params = nothing, R_params = nothing, PDEkwargs...) where {T1<:AbstractVector}\n\nPerform bootstrapping on the data (x, t, u) to learn the appropriate functional forms of  (T, D, R) with uncertainty, using the basis function approach.\n\nArguments\n\nx::T1: The spatial data.\nt::T1: The temporal data.\nu::T1: The density data.\nD::Vector{Function}: The diffusion function, given in the form D(u, β, D_params).\nD′::Vector{Function}: The derivative of the diffusion function, given in the form D′(u, β, D_params).\nR::Vector{Function}: The reaction function, given in the form R(u, γ, R_params).\nR′::Vector{Function}: The derivative of the reaction function, given in the form R′(u, γ, R_params).\n\nKeyword Arguments\n\ngp_setup::GP_Setup = GP_Setup(u): Defines the setup for the Gaussian process. See also GP_Setup.\nbootstart_setup::Bootstrap_Setup = Bootstrap_Setup(x, t, u): Defines some extra keyword arguments for the bootstrapping and optimisation process. See also Bootstrap_Setup.\npde_setup::PDE_Setup = PDE_Setup(x): Defines some extra keyword arguments for the PDE solutions. See also PDE_Setup.\nD_params = nothing: Extra known parameters for the diffusion function D.\nR_params = nothing: Extra known parameters for the reaction function R.\nPDEkwargs...: Extra keyword arguments to use inside DifferentialEquations.solve.\n\nOutputs\n\nbgp: A BasisBootResults structure. See BasisBootResults. \n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.basis_bootstrap_helper-NTuple{7, Any}","page":"Index","title":"EquationLearning.basis_bootstrap_helper","text":"basis_bootstrap_helper(x, t, bootₓ, bootₜ, d, r, B)\n\nComputes all the required cache arrays and certain parameter values for the basis bootstrapping process. \n\nArguments\n\nx: The original spatial data. \nt: The original temporal data.\nbootₓ: The spatial bootstrapping grid.\nbootₜ: The temporal bootstrapping grid.\nd: Number of diffusion parameters. \nr: Number of reaction parameters.\nB: Number of bootstrap iterations being performed.\n\nOutputs\n\nThe outputs are broken into categories.\n\nBootstrapping computation:\n\nx_min: The minimum x value.\nt_min: The minimum t value.\nx_rng: The range of the x values, x_max - x_min.\nt_rng: The range of the t values, t_max - t_min.\nXₛ: The test matrix for the bootstrapping grid data.\n\nFunctions:\n\nf: Cache array for f(x, t).\nfₜ: Cache array for fₜ(x, t).\nfₓ: Cache array for fₓ(x, t).\nfₓₓ: Cache array for fₓₓ(x, t).\nffₜfₓfₓₓ: Cache array for the stacked vector [f; fₜ; fₓ; fₓₓ].\nf_idx: Indices for extracting f(x, t) from ffₜfₓfₓₓ from the random samples. \nfₜ_idx: Indices for extracting fₜ(x, t) from ffₜfₓfₓₓ from the random samples.\nfₓ_idx: Indices for extracting fₓ(x, t) from ffₜfₓfₓₓ from the random samples.\nfₓₓ_idx: Indices for extracting fₓₓ(x, t) from ffₜfₓfₓₓ from the random samples.\n\nBases:\n\ndiffusionBases: Matrix for storing the computed diffusion coefficients. Each column represents a set of parameters.\nreactionBases: Matrix for storing the computed reaction coefficients. Each column represents a set of parameters.\n\nSamples:\n\nℓz: Cache array for storing the result of the matrix-vector product Lz, where L is the Cholesky factor and z is a random sample from N(0, I).\nzvals: Matrix for storing the drawn z values from N(0, I).\n\nOther caches\n\nDu: Cache array for computing D(u).\nD′u: Cache array for computing D′(u).\nRu: Cache array for computing R(u).\nR′u: Cache array for computing R′(u).\nA: Matrix for the linear system giving the coefficients.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.basis_learn_equations!-NTuple{15, Any}","page":"Index","title":"EquationLearning.basis_learn_equations!","text":"basis_learn_equations!(f, fₜ, fₓ, fₓₓ, D, D′, R, \n    db, rb, d, r, A, \n    D_params, R_params, inIdx)\n\nEstimates the coefficients db and rb for diffusion and reaction.\n\nArguments\n\nf: Estimates for the learned function f of the reaction-diffusion process.\nfₓ: Derivatives of f in x at the same gridpoints.\nfₓₓ: Second derivatives of f in x at the same gridpoints.\nfₜ: Derivatives of f in t at the same gridpoints.\nD: The basis functions for the diffusion curve, provided as a vector of functions.\nD′: The derivatives for the basis functions φ, provided as a vector of functions. (These are φ′ = d/du[φ(u)], so do not divide these by K.)\nR: The basis functions for the reaction curve, provided as a vector of functions.\ndb: Cache array for the basis coefficients for diffusion.\nrb: Cache array for the basis coefficients for reaction.\nd: Number of diffusion parameters.\nr: Number of reaction parameters.\nA: Cache matrix for the coefficient matrix.\nD_params: Known diffusion parameters. \nR_params: Known reaction parameters.\ninIdx: Values to use. See data_thresholder.\n\nOutputs\n\ndb and rb are updated in-place with the diffusion and reaction coefficients, respectively.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.basis_sysdegeneral!-NTuple{4, Any}","page":"Index","title":"EquationLearning.basis_sysdegeneral!","text":"basis_sysdegeneral!(dudt, u, p, t)\n\nFunction for computing the system of ODEs used in a discretised delay-reaction-diffusion PDE.\n\nArguments\n\ndudt: A cache array used for storing the left-hand side of the system of ODEs. \nu: The current values for the variables in the systems.\np: A tuple of parameters, given by:\np[1] = N: Number of mesh points being used for solving the PDE.\np[2] = V: The volume of each cell in the discretised PDE.\np[3] = h: The spacing between cells in the discretised PDE.\np[4] = a₀: The coefficient on u(a, t) in the Robin boundary condition at x = a (the left end-point of the mesh). \np[5] = b₀: The coefficient on -∂u(a, t)/∂x in the Robin boundary condition at x = a (the left end-point of the mesh).\np[6] = c₀: The right-hand side constant in the Robin boundary condition at x = a (the left end-point of the mesh).\np[7] = a₁: The coefficient on u(b, t) in the Robin boundary condition at x = b (the right end-point of the mesh). \np[8] = b₁: The coefficient on ∂u(b, t)/∂t in the Robin boundary condition at x = b (the right end-point of the mesh).\np[9] = c₁: The right-hand side constant in the Robin boundary condition at x = b (the right end-point of the mesh).\np[10] = DD: Cache array used for storing the values of the diffusion function D at D(u).\np[11] = RR: Cache array used for storing the values of the reaction function R at R(u).\np[12] = DD′: Cache array used for storing the values of the derivative of the diffusion function D at D′(u).\np[13] = RR′: Cache array used for storing the values of the derivative of the reaction function R at R′(u).\np[14] = D: The diffusion function, given in the form D(u, β, D_params).\np[15] = R: The reaction function, given in the form R(u, γ, R_params).\np[16] = D′: The derivative of the diffusion function, given in the form D′(u, β, D_params).\np[17] = R′: The derivative of the reaction function, given in the form R′(u, γ, R_params).\np[18] = db: The values of the diffusion parameters.\np[19] = rb: The values of the reaction parameters.\np[20] = D_params: Extra parameters used in the diffusion function.\np[21] = R_params: Extra parameters for the reaction function.\np[22] = A₁: A cache array used when computing the values of the diffusion function at a point u. Must be the same length as meshPoints.\np[23] = A₂: A cache array used when computing the values of the reaction function at a point u. Must be the same length as meshPoints.\nt: The current time value.\n\nOutputs\n\nThe values are updated in-place into the vector dudt for the new value of dudt at time t.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.boot_pde_solve-Tuple{BasisBootResults, Any, Any, Any}","page":"Index","title":"EquationLearning.boot_pde_solve","text":"boot_pde_solve(bgp::BasisBootResults, x_pde, t_pde, u_pde; prop_samples = 1.0, ICType = \"data\")\n\nSolve the PDEs corresponding to the bootstrap iterates in bgp obtained from basis_bootstrap_gp. \n\nArguments\n\nbgp::BasisBootResults: A BasisBootResults struct containing the results from basis_bootstrap_gp.\nx_pde: The spatial data to use for obtaining the initial condition.\nt_pde: The temporal data to use for obtaining the initial condition.\nu_pde: The density data to use for obtaining the initial condition.\n\nKeyword Arguments\n\nprop_samples = 1.0: The proportion of bootstrap samples to compute teh corresponding PDE soluton to.\nICType = \"data\": The type of initial condition to use. Should be either \"data\" or \"gp\".\n\nOutputs\n\nsolns_all: The solutions to the PDEs over the mesh points at each time value.\n\nNote\n\nThe _pde subscript is used to indicate that these data need not be the same as the (x, t, u) used in bootstrap_gp, for example. For example, we may have 3 replicates of some data which we would easily use in bootstrap_gp, but for the PDE we would need to average these  together for obtaining the solutions.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.compute_valid_pde_indices-Tuple{Any, Any, Any, Any, BasisBootResults}","page":"Index","title":"EquationLearning.compute_valid_pde_indices","text":"compute_valid_pde_indices(u_pde, num_t, num_u, nodes, weights, bgp::BasisBootResults)\n\nMethod for calling [compute_valid_pde_indices] when providing only bgp and the data. \n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.compute_valid_pde_indices-Tuple{BasisBootResults, Any, Any, Any, Any, Any, Any, Any, Any, Any}","page":"Index","title":"EquationLearning.compute_valid_pde_indices","text":"compute_valid_pde_indices(bgp, u_pde, num_t, num_u, B, tr, dr, rr, nodes, weights, D_params, R_params, T_params)\n\nComputes the indices corresponding to the bootstrap samples which give valid PDE solutions. The check is done by  ensuring that the delay and diffusion values are strictly nonnegative, and the area under the reaction curve is nonnegative.\n\nArguments\n\nbgp::BasisBootResults: The bootstrapping results.\nu_pde: The density data used for fitting the original Gaussian process. See also fit_GP.\nnum_u: The number of density values to use for checking the validity of the diffusion function values.\nB: The number of bootstrap samples used.\ndr: The matrix of estimated diffusion parameters.\nrr: The matrix of estimated reaction parameters.\nnodes: Gauss-Legendre quadrature nodes.\nweights: Gauss-Legendre quadrature weights.\nD_params: Extra parameters for the diffusion function.\nR_params: Extra parameters for the reaction function. \n\nOutputs\n\nidx: The vector of indices corresponding to valid bootstrap samples.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.curve_results-Tuple{BasisBootResults}","page":"Index","title":"EquationLearning.curve_results","text":"curve_results(bgp::BasisBootResults; <keyword arguments>)\n\nPlots the learned functional forms along with confidence intervals for the bootstrapping results in bgp from the basis function approach.\n\nArguments\n\nbgp: A BasisBootResults object which contains the results for the bootstrapping. \n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nfontsize = 23: Font size for the plots (to be used in plot_aes!).\nx_scale = 1.0: Value used for scaling the spatial data (and all other length units, e.g. for diffusion).\nt_scale = 1.0: Value used for scaling the temporal data (and all other time units, e.g. for reaction).\n\nOutputs\n\ndiffusionCurvePlots: A plot containing the learned functional form for the diffusion function, along with an uncertainty ribbon.\nreactionCurvePlots: A plot containing the learned functional form for the reaction function, along with an uncertainty ribbon.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.curve_values-Tuple{BasisBootResults}","page":"Index","title":"EquationLearning.curve_values","text":"curve_values(bgp::BasisBootResults; <keyword arguments>)\n\nComputes values for plotting the learned functional forms along with confidence intervals for the bootstrapping results in bgp from the basis function approach.\n\nArguments\n\nbgp: A BasisBootResults object which contains the results for the bootstrapping. \n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nx_scale = 1.0: Value used for scaling the spatial data (and all other length units, e.g. for diffusion).\nt_scale = 1.0: Value used for scaling the temporal data (and all other time units, e.g. for reaction).\n\nOutputs\n\nDu_vals: Ribbon features for the diffusion functions.\nRu_vals: Ribbon features for the reaction functions.\nu_vals: The density values used for computing the functions. \nt_vals: The time values used for computing the functions.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.density_results-Tuple{BasisBootResults}","page":"Index","title":"EquationLearning.density_results","text":"density_results(bgp::BasisBootResults; <keyword arguments>)\n\nPlots the densities for the bootstrapping results in bgp with the basis function approach.\n\nArguments\n\nbgp: A BasisBootResults object which contains the results for the bootstrapping. \n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nfontsize = 23: Font size for the plots (to be used in plot_aes!).\ndiffusion_scales = nothing: Values that multiply the individual diffusion parameters. \nreaction_scales = nothing: Values that multiply the individual reaction parameters.\ndiffusion_resolution = (800, 800): Resolution for the diffusion figure.\nreaction_resolution = (800, 800): Resolution for the reaction figure.\n\nOutputs\n\ndiffusionDensityFigure: A figure of plots containing a density plot for each diffusion parameter.\nreactionDensityFigure: A figure of plots containing a density plot for each reaction parameter.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.density_values-Tuple{BasisBootResults}","page":"Index","title":"EquationLearning.density_values","text":"density_values(bgp::BasisBootResults; <keyword arguments>)\n\nComputes the densities for the bootstrapping results in bgp from a basis function approach.\n\nArguments\n\nbgp: A BasisBootResults object which contains the results for the bootstrapping. \n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nfontsize = 23: Font size for the plots (to be used in plot_aes!).\ndiffusion_scales = nothing: Values that multiply the individual diffusion parameters. \nreaction_scales = nothing: Values that multiply the individual reaction parameters.\n\nOutputs\n\ndr: Diffusion densities. \nrr: Reaction densities. \nd: Number of diffusion parameters.\nr: Number of reaction parameters. \ndelayCIs: Confidence intervals for the delay parameters. \ndiffusionCIs: Confidence intervals for the diffusion parameters. \nreactionCIS: Confidence intervals for the reaction parameters.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.evaluate_basis!-NTuple{6, Any}","page":"Index","title":"EquationLearning.evaluate_basis!","text":"evaluate_basis!(val, coefficients, basis, point, A)\n\nEvaluates the function func(u) = ∑_(i=1)^n coefficients[i]basis[i](u) at the point u = point and puts it into val. This function differs from evaluateBasis as it works directly on vectors and uses matrix multiplication rather than dot products (although they are equivalent). The function uses @inline to suggest that the compiler could inline this in the LLVM.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.evaluate_basis-NTuple{4, Any}","page":"Index","title":"EquationLearning.evaluate_basis","text":"evaluate_basis(coefficients, basis, point)\n\nEvaluates the function func(u) = ∑_(i=1)^n coefficients[i]basis[i](u) at the point u = point.  The function uses @inline to suggest that the compiler could inline this in the LLVM.\n\n\n\n\n\n","category":"method"},{"location":"index.html#bootstrapping.jl","page":"Index","title":"bootstrapping.jl","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"Modules = [EquationLearning]\nPages = [\"bootstrapping.jl\"]","category":"page"},{"location":"index.html#EquationLearning.bootstrap_gp-Union{Tuple{T1}, Tuple{T1, T1, T1, Function, Function, Function, Function, Function, T1, T1, T1, T1, T1}} where T1<:(AbstractVector)","page":"Index","title":"EquationLearning.bootstrap_gp","text":"bootstrap_gp(x::T1, t::T1, u::T1,\n    T::Function, D::Function, D′::Function, R::Function,\n    α₀::T1, β₀::T1, γ₀::T1, lowers::T1, uppers::T1;\n    gp_setup::GP_Setup = GP_Setup(u),\n    bootstrap_setup::Bootstrap_Setup = Bootstrap_Setup(x, t, u),\n    optim_setup::Optim.Options = Optim.Options(),\n    pde_setup::PDE_Setup = PDE_Setup(x),\n    D_params = nothing, R_params = nothing, T_params = nothing, zvals = nothing, PDEkwargs...) where {T1<:AbstractVector}\n\nPerform bootstrapping on the data (x, t, u) to learn the appropriate functional forms of  (T, D, R) with uncertainty. \n\nArguments\n\nx::T1: The spatial data.\nt::T1: The temporal data.\nu::T1: The density data.\nT::Function: The delay function, given in the formT(t, α, T_params)`.\nD::Function: The diffusion function, given in the form D(u, β, D_params).\nD′::Function: The derivative of the diffusion function, given in the form D′(u, β, D_params).\nR::Function: The reaction function, given in the form R(u, γ, R_params).\nR′::Function: The derivative of the reaction function, given in the form R′(u, γ, R_params).\nα₀::T1: Initial estimates of the delay parameters. Not actually used for anything other than ensuring the functions are specified correctly.\nβ₀::T1: Initial estimates of the diffusion parameters. Not actually used for anything other than ensuring the functions are specified correctly. \nγ₀::T1: Initial estimates of the reaction parameters. Not actually used for anything other than ensuring the functions are specified correctly. \nlowers::T1: Lower bounds to use for constructing the Latin hypersquare design, and for the constrained problem if constrained = true in bootstrap_setup.\nuppers::T1: Upper bounds to use for constructing the Latin hypersquare design, and for the constrained problem if constrained = true in bootstrap_setup.\n\nKeyword Arguments\n\ngp_setup::GP_Setup = GP_Setup(u): Defines the setup for the Gaussian process. See also GP_Setup.\nbootstart_setup::Bootstrap_Setup = Bootstrap_Setup(x, t, u): Defines some extra keyword arguments for the bootstrapping and optimisation process. See also Bootstrap_Setup.\noptim_setup::Optim.Options = Optim_Options(): Defines some options when using Optim.optimize.\npde_setup::PDE_Setup = PDE_Setup(x): Defines some extra keyword arguments for the PDE solutions. See also PDE_Setup.\nD_params = nothing: Extra known parameters for the diffusion function D.\nR_params = nothing: Extra known parameters for the reaction function R.\nT_params = nothing: Extra known parameters for the delay function T.\nPDEkwargs...: Extra keyword arguments to use inside DifferentialEquations.solve.\n\nOutputs\n\nbgp: A BootResults structure. See BootResults. \n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.bootstrap_grid-NTuple{4, Any}","page":"Index","title":"EquationLearning.bootstrap_grid","text":"bootstrap_grid(x, t, bootₓ, bootₜ)\n\nComputes the grid used for bootstrapping. See also bootstrap_helper and bootstrap_gp.\n\nArguments\n\nx: The original spatial data. \nt: The original temporal data.\nbootₓ: The spatial bootstrapping grid.\nbootₜ: The temporal bootstrapping grid.\n\nOutputs\n\nx_min: The minimum x value.\nx_max: The maximum x value.\nt_min: The minimum t value.\nt_max: The maximum t value.\nx_rng: The range of the x values, x_max - x_min.\nt_rng: The range of the t values, t_max - t_min.\nXₛ: The test matrix for the bootstrapping grid data.\nunscaled_t̃: The unscaled t values for the bootstrapping grid. Used for computing the loss function later.\nnₓnₜ: The number of test data points.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.bootstrap_helper-NTuple{16, Any}","page":"Index","title":"EquationLearning.bootstrap_helper","text":"bootstrap_helper(x, t, bootₓ, bootₜ, α₀, β₀, γ₀, B, num_restarts, meshPoints, δt, finalTime, gp, lowers, uppers)\n\nComputes all the required cache arrays and certain parameter values for the bootstrapping process.  The function simply calls bootstrap_grid, preallocate_bootstrap, and preallocate_eqlearn. See also  bootstrap_gp.\n\nArguments\n\nx: The original spatial data. \nt: The original temporal data.\nbootₓ: The spatial bootstrapping grid.\nbootₜ: The temporal bootstrapping grid.\nα₀: Initial values for the delay coefficients. (Not actually used anywhere other than for computing the number of delay parameters and checking arguments.)\nβ₀: Initial values for the diffusion coefficients. (Not actually used anywhere other than for computing the number of diffusion parameters and checking arguments.)\nγ₀: Initial values for the reaction coefficients. (Not actually used anywhere other than for computing the number of reaction parameters and checking arguments.)\nB: Number of bootstrap iterations being performed.\nnum_restarts: Number of times to restart the optimisation problem when solving the nonlinear least squares problems. See learn_equations!.\nmeshPoints: The spatial mesh used for solving the PDEs.\nδt: A number or a vector specifying the spacing between returned times for the solutions to the PDEs or specific times, respectively.\nfinalTime: The final time to give the solution to the PDEs at.\ngp: The fitted Gaussian process. See fit_GP.\nlowers: Lower bounds for the delay, diffusion, and reaction parameters (in that order) for constructing the Latin hypercube design (only for the grid, these do not constrain the parameter values).\nuppers: Upper bounds for the delay, diffusion, and reaction parameters (in that order) for constructing the Latin hypercube design (only for the grid, these do not constrain the parameter values).\n\nOutputs\n\nThe outputs are broken into categories.\n\nBootstrapping computation:\n\nx_min: The minimum x value.\nx_max: The maximum x value.\nt_min: The minimum t value.\nt_max: The maximum t value.\nx_rng: The range of the x values, x_max - x_min.\nt_rng: The range of the t values, t_max - t_min.\nXₛ: The test matrix for the bootstrapping grid data.\nunscaled_t̃: The unscaled t values for the bootstrapping grid. Used for computing the delay function in the loss function.\nnₓnₜ: The number of test data points.\n\nFunctions:\n\nf: Cache array for f(x, t).\nfₜ: Cache array for fₜ(x, t).\nfₓ: Cache array for fₓ(x, t).\nfₓₓ: Cache array for fₓₓ(x, t).\nffₜfₓfₓₓ: Cache array for the stacked vector [f; fₜ; fₓ; fₓₓ].\nf_idx: Indices for extracting f(x, t) from ffₜfₓfₓₓ from the random samples. \nfₜ_idx: Indices for extracting fₜ(x, t) from ffₜfₓfₓₓ from the random samples.\nfₓ_idx: Indices for extracting fₓ(x, t) from ffₜfₓfₓₓ from the random samples.\nfₓₓ_idx: Indices for extracting fₓₓ(x, t) from ffₜfₓfₓₓ from the random samples.\n\nBases:\n\ntt: Number of delay parameters.\nd: Number of diffusion parameters.\nr: Number of reaction parameters.\ndelayBases: Matrix for storing the computed delay coefficients. Each column represents a set of parameters.\ndiffusionBases: Matrix for storing the computed diffusion coefficients. Each column represents a set of parameters.\nreactionBases: Matrix for storing the computed reaction coefficients. Each column represents a set of parameters.\n\nSamples:\n\nℓz: Cache array for storing the result of the matrix-vector product Lz, where L is the Cholesky factor and z is a random sample from N(0, I).\nzvals: Matrix for storing the drawn z values from N(0, I).\n\nOptimisation:\n\nobj_values: Cache array for storing the objective function values at each optimisation restart.\nstacked_params: Matrix which stores parameter values at each optimisation restart. The columns take the form [α; β; γ].\n\nPDE geometry:\n\nN: The length of meshPoints.\nΔx: The spacing between each point in meshPoints.\nV: The volume of each cell in the spatial mesh.\n\nPDE computation:\n\nDu: Cache array for computing D(u).\nD′u: Cache array for computing D′(u).\nRu: Cache array for computing R(u).\nR′u: Cache array for computing R′(u).\nTuP: Cache array for storing the values of the delay function at the unscaled times (for the \"PDE\" loss function).\nDuP: Cache array for storing the values of the diffusion function at the estimated density values (for the \"PDE\" loss function).\nD′uP: Cache array for storing the values of the derivative of the diffusion function at the estimated density values (for the \"PDE\" loss function).\nRuP: Cache array for storing the values of the reaction function at the estimated density values (for the \"PDE\" loss function).\nR′uP: Cache array for storing the values of the derivative of the reaction function at the estimated density values (for the \"PDE\" loss function).\nRuN: For storing values of the reaction function at Gauss-Legendre quadrature nodes.\n\nPDE loss function:\n\nSSEArray: Cache array for storing the solutions to the PDEs.\nXₛ₀: Logical array used for accessing the values in Xₛ corresponding to the initial condition.\nIC1: Cache array for storing the initial spline over the initial data.\ninitialCondition: Cache array for storing the initial condition over meshPoints.\nMSE: Cache array for storing the individual squared errors.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.bootstrap_helper-Tuple{Any, Any, Any, Any, Any, Any, Any, GP_Setup, Bootstrap_Setup, PDE_Setup, Any}","page":"Index","title":"EquationLearning.bootstrap_helper","text":"bootstrap_helper(x, t, α₀, β₀, γ₀, lowers, uppers, gp_setup::GP_Setup, bootstrap_setup::Bootstrap_Setup, pde_setup::PDE_Setup)\n\nMethod for calling bootstrap_helper using the setup structs from GP_Setup, Bootstrap_Setup, and PDE_Setup. \n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.preallocate_bootstrap-NTuple{6, Any}","page":"Index","title":"EquationLearning.preallocate_bootstrap","text":"preallocate_bootstrap(nₓnₜ, α₀, β₀, γ₀, B)\n\nCreates cache arrays and computes certain parameters  that are used for the bootstrapping component. See bootstrap_helper for details and bootstrap_gp for its use. \n\nArguments\n\nnₓnₜ: The number of test data points.\nα₀: Initial values for the delay coefficients. (Not actually used anywhere other than for computing the number of delay parameters and checking arguments.)\nβ₀: Initial values for the diffusion coefficients. (Not actually used anywhere other than for computing the number of diffusion parameters and checking arguments.)\nγ₀: Initial values for the reaction coefficients. (Not actually used anywhere other than for computing the number of reaction parameters and checking arguments.)\nB: Number of bootstrap iterations being performed.\n\nOutputs\n\nf: Cache array for f(x, t).\nfₜ: Cache array for fₜ(x, t).\nfₓ: Cache array for fₓ(x, t).\nfₓₓ: Cache array for fₓₓ(x, t).\nffₜfₓfₓₓ: Cache array for the stacked vector [f; fₜ; fₓ; fₓₓ].\nf_idx: Indices for extracting f(x, t) from ffₜfₓfₓₓ from the random samples. \nfₜ_idx: Indices for extracting fₜ(x, t) from ffₜfₓfₓₓ from the random samples.\nfₓ_idx: Indices for extracting fₓ(x, t) from ffₜfₓfₓₓ from the random samples.\nfₓₓ_idx: Indices for extracting fₓₓ(x, t) from ffₜfₓfₓₓ from the random samples.\ntt: Number of delay parameters.\nd: Number of diffusion parameters.\nr: Number of reaction parameters.\ndelayBases: Matrix for storing the computed delay coefficients. Each column represents a set of parameters.\ndiffusionBases: Matrix for storing the computed diffusion coefficients. Each column represents a set of parameters.\nreactionBases: Matrix for storing the computed reaction coefficients. Each column represents a set of parameters.\nℓz: Cache array for storing the result of the matrix-vector product Lz, where L is the Cholesky factor and z is a random sample from N(0, I).\nzvals: Matrix for storing the drawn z values from N(0, I).\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.preallocate_eqlearn-NTuple{12, Any}","page":"Index","title":"EquationLearning.preallocate_eqlearn","text":"preallocate_eqlearn(num_restarts, σ₁, σ₂, σ₃, meshPoints, δt, finalTime, Xₛ, tt, d, r, nₓnₜ, gp)\n\nCreates cache arrays and computes certain parameters that are used for the bootstrapping component.  See bootstrap_helper for details and bootstrap_gp for its use. \n\nArguments\n\nnum_restarts: Number of times to restart the optimisation problem when solving the nonlinear least squares problems. See learn_equations!.\nmeshPoints: The spatial mesh used for solving the PDEs.\nδt: A number or a vector specifying the spacing between returned times for the solutions to the PDEs or specific times, respectively.\nfinalTime: The final time to give the solution to the PDEs at.\nXₛ: The test matrix for the bootstrapping grid data.\ntt: Number of delay parameters.\nd: Number of diffusion parameters.\nr: Number of reaction parameters.\nnₓnₜ: The number of test data points.\ngp: The fitted Gaussian process. See fit_GP.\nlowers: Lower bounds for the delay, diffusion, and reaction parameters (in that order) for constructing the Latin hypercube design (only for the grid, these do not constrain the parameter values).\nuppers: Upper bounds for the delay, diffusion, and reaction parameters (in that order) for constructing the Latin hypercube design (only for the grid, these do not constrain the parameter values).\n\nOutputs\n\nobj_values: Cache array for storing the objective function values at each optimisation restart.\nstacked_params: Matrix which stores parameter values at each optimisation restart. The columns take the form [α; β; γ].\nN: The length of meshPoints.\nΔx: The spacing between each point in meshPoints.\nV: The volume of each cell in the spatial mesh.\nDu: Cache array for computing D(u).\nD′u: Cache array for computing D′(u).\nRu: Cache array for computing R(u).\nR′u: Cache array for computing R′(u).\nTuP: Cache array for storing the values of the delay function at the unscaled times (for the \"PDE\" loss function).\nDuP: Cache array for storing the values of the diffusion function at the estimated density values (for the \"PDE\" loss function).\nD′uP: Cache array for storing the values of the derivative of the diffusion function at the estimated density values (for the \"PDE\" loss function).\nR′uP: Cache array for storing the values of the derivative of the reaction function at the estimated density values (for the \"PDE\" loss function).\nRuP: Cache array for storing the values of the reaction function at the estimated density values (for the \"PDE\" loss function).\nRuN: For storing values of the reaction function at Gauss-Legendre quadrature nodes.\nSSEArray: Cache array for storing the solutions to the PDEs.\nXₛ₀: Logical array used for accessing the values in Xₛ corresponding to the initial condition.\nIC1: Cache array for storing the initial spline over the initial data.\ninitialCondition: Cache array for storing the initial condition over meshPoints.\nMSE: Cache array for storing the individual squared errors.\n\n\n\n\n\n","category":"method"},{"location":"index.html#comparison.jl","page":"Index","title":"comparison.jl","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"Modules = [EquationLearning]\nPages = [\"comparison.jl\"]","category":"page"},{"location":"index.html#EquationLearning.AIC-Tuple{Union{BasisBootResults, BootResults}, Any, Any, Any}","page":"Index","title":"EquationLearning.AIC","text":"AIC(bgp::Union{BootResults, BasisBootResults}; correct = true)\n\nComputes all the AIC values for the results in bgp. A small-sample size correction is used  if correct = true. The formulas used are given in Eq. 6 (uncorrected) or Eq. 17 (corrected) of Banks and Joyner (2017) [https://doi.org/10.1016/j.aml.2017.05.005].\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.classify_Δᵢ-Tuple{Float64}","page":"Index","title":"EquationLearning.classify_Δᵢ","text":"classify_Δᵢ(Δᵢ::Float64)\n\nClassifies Δᵢ, the AICᵢ difference AICᵢ - AICₘᵢₙ, based on the guidelines by Burnham and Anderson, 2004:\n\nΔᵢ ≤ 3.0: Returns 1, meaning there is substantial evidence that this model is the optimal model.\n3.0 < Δᵢ ≤ 8.0: Returns 2, meaning there is considerably less evidence in favour of this model being optimal.\nΔᵢ > 8.0: Returns 3, meaning there is essentially no evidence that this model is optimal.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.compare_AICs-Tuple{Any, Any, Any, Vararg{Union{BasisBootResults, BootResults}}}","page":"Index","title":"EquationLearning.compare_AICs","text":"compare_AICs(x, t, u, models::Union{BootResults, BasisBootResults}...; correct = true)\n\nCompare several bootstrapped models using AIC.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.compare_AICs-Tuple{Vararg{Float64}}","page":"Index","title":"EquationLearning.compare_AICs","text":"compare_AICs(AICs::Float64...)\n\nCompares the AIC values in AICs.... See also classify_Δᵢ and AIC.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.compare_AICs-Tuple{Vararg{Vector{Float64}}}","page":"Index","title":"EquationLearning.compare_AICs","text":"compare_AICs(AICs::Vector{Float64}...)\n\nCompares many AICs by comparing entry-wise. The results are averaged. Assumes that each AIC is of equal length,  otherwise computes only up to the minimum length.\n\n\n\n\n\n","category":"method"},{"location":"index.html#gps.jl","page":"Index","title":"gps.jl","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"Modules = [EquationLearning]\nPages = [\"gps.jl\"]","category":"page"},{"location":"index.html#EquationLearning.compute_joint_GP-Tuple{GaussianProcesses.GPBase, Any}","page":"Index","title":"EquationLearning.compute_joint_GP","text":"compute_joint_GP(gp::GPBase, X̃; nugget = 1e-10)\n\nComputes the mean vector μ and Cholesky factor L such that LLᵀ = Σ, where \n\nleftbeginarrayc mathbff  fracpartialmathbf fpartial t  fracpartialmathbf fpartial x fracpartial^2mathbf fpartial x^2endarrayright sim mathcal Nleft(mathbfmu mathbfSigmaright)\n\nArguments\n\ngp::GPBase: The fitted Gaussian process. \nX̃: Test data for the Gaussian process. \n\nKeyword Arguments\n\nnugget = 1e-10: The term to add to the diagonals of the covariance matrix in case the matrix is not positive definite.\n\nOutputs\n\nμ: The mean vector. \nL: The Cholesky factor of the covariance matrix.\n\nExtended help\n\nThe covariance matrices are built without any attention to symmetry. The loops could be optimised by  e.g. considering only the upper triangular components. \n\nThe covariance matrices are built using separate functions for the derivatives of the kernel function (currently  only implemented for the squared exponential kernel). These functions are:\n\ndkxⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd²kxⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\ndktⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\ndktᵢ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd²ktᵢtⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd²ktᵢxⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd³tᵢxⱼ²(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\ndkxᵢ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd²kxᵢtⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd²kxᵢxⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd³kxᵢxⱼ²(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd²kxᵢ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd³kxᵢ²tⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd³kxᵢ²xⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd⁴kxᵢ²xⱼ²(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\n\nIn these functions, the derivatives are evaluated at ([x₁; t₁], [x₂; t₂]) with length scales  (ℓ₁, ℓ₂) for space and time, respectively. The functions are missing a multiplication by the  kernel value cov(gp.kernel, [x₁; t₁], [x₂; t₂]) to allow for it to be done in place more easily.  Note also that in some of these functions, powers are written as products, e.g. x³ = x*x*x, to allow  for the @muladd macro to work (see https://github.com/SciML/MuladdMacro.jl). Since the functions are  quite small, we use @inline on each function to encourage the compiler to inline the function  in the LLVM.\n\nYou may get a StackOverflowError from this function. This may be related to https://github.com/JuliaLang/julia/issues/43242, in which case you can set the number of BLAS threads to 1:\n\njulia> ccall((:openblas_get_num_threads64_, Base.libblas_name), Cint, ()) # In case you need to remember how many threads you used prior\njulia> LinearAlgebra.BLAS.set_num_threads(1)\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.dktᵢ-NTuple{6, Any}","page":"Index","title":"EquationLearning.dktᵢ","text":"See compute_joint_GP for details.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.dktⱼ-NTuple{6, Any}","page":"Index","title":"EquationLearning.dktⱼ","text":"See compute_joint_GP for details.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.dkxᵢ-NTuple{6, Any}","page":"Index","title":"EquationLearning.dkxᵢ","text":"See compute_joint_GP for details.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.dkxⱼ-NTuple{6, Any}","page":"Index","title":"EquationLearning.dkxⱼ","text":"See compute_joint_GP for details.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.draw_gp!-Tuple{Any, Any, LinearAlgebra.LowerTriangular, Any, Any}","page":"Index","title":"EquationLearning.draw_gp!","text":"draw_gp!(F, μ, L::LowerTriangular, z, ℓz)\n\nDraws a random sample from a Gaussian process with mean μ and  covariance matrix Σ = LLᵀ corresponding to z ∼ N(0, I).\n\nArguments\n\nF: Cache array used for storing the random sample.\nμ: The mean vector.\nL::LowerTriangular: The Cholesky factor of the covariance matrix.\nz: The random sample from z ∼ N(0, I).\nℓz: Cache array for storing the result of the matrix-vector product Lz.\n\nOutputs\n\nThe random sample is updated in-place into F.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.d²ktᵢtⱼ-NTuple{6, Any}","page":"Index","title":"EquationLearning.d²ktᵢtⱼ","text":"See compute_joint_GP for details.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.d²ktᵢxⱼ-NTuple{6, Any}","page":"Index","title":"EquationLearning.d²ktᵢxⱼ","text":"See compute_joint_GP for details.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.d²kxᵢ-NTuple{6, Any}","page":"Index","title":"EquationLearning.d²kxᵢ","text":"See compute_joint_GP for details.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.d²kxᵢtⱼ-NTuple{6, Any}","page":"Index","title":"EquationLearning.d²kxᵢtⱼ","text":"See compute_joint_GP for details.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.d²kxᵢxⱼ-NTuple{6, Any}","page":"Index","title":"EquationLearning.d²kxᵢxⱼ","text":"See compute_joint_GP for details.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.d²kxⱼ-NTuple{6, Any}","page":"Index","title":"EquationLearning.d²kxⱼ","text":"See compute_joint_GP for details.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.d³kxᵢxⱼ²-NTuple{6, Any}","page":"Index","title":"EquationLearning.d³kxᵢxⱼ²","text":"See compute_joint_GP for details.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.d³kxᵢ²tⱼ-NTuple{6, Any}","page":"Index","title":"EquationLearning.d³kxᵢ²tⱼ","text":"See compute_joint_GP for details.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.d³kxᵢ²xⱼ-NTuple{6, Any}","page":"Index","title":"EquationLearning.d³kxᵢ²xⱼ","text":"See compute_joint_GP for details.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.d³tᵢxⱼ²-NTuple{6, Any}","page":"Index","title":"EquationLearning.d³tᵢxⱼ²","text":"See compute_joint_GP for details.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.d⁴kxᵢ²xⱼ²-NTuple{6, Any}","page":"Index","title":"EquationLearning.d⁴kxᵢ²xⱼ²","text":"See compute_joint_GP for details.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.fit_GP-Tuple{Any, Any, Any, GP_Setup}","page":"Index","title":"EquationLearning.fit_GP","text":"fit_GP(x, t, u, setup::GP_Setup)\n\nMethod for calling fit_GP with a setup defined by GP_Setup.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.fit_GP-Tuple{Any, Any, Any}","page":"Index","title":"EquationLearning.fit_GP","text":"fit_GP(x, t, u; <keyword arguments>)\n\nFits a Gaussian process with data (x, t) using the targets in u. \n\nArguments\n\nx: The spatial data. \nt: The temporal data.\nu: The targets corresponding to (x, t).\n\nKeyword Arguments\n\nℓₓ = log.([1e-4, 1.0]): A 2-vector giving the lower and upper bounds for the initial estimates of ℓₓ (defined on a log scale).\nℓₜ = log.([1e-4, 1.0]): A 2-vector giving the lower and upper bounds for the initial estimates of ℓₜ (defined on a log scale).\nσ = log.([1e-1, 2std(u)]): A 2-vector giving the lower and upper bounds for the initial estimates of σ (defined on a log scale).\nσₙ = log.([1e-5, 2std(u)]): A 2-vector giving the lower and upper bounds for the initial estimates of σₙ (defined on a log scale).\nnum_restarts = 50: Number of times to restart the optimiser. See opt_restart!.\n\nOutputs\n\ngp: The fitted Gaussian process.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.opt_restart!-NTuple{5, Any}","page":"Index","title":"EquationLearning.opt_restart!","text":"opt_restart!(gp, ℓₓ, ℓₜ, σ, σₙ; num_restarts = 50)\n\nGiven a Gaussian process gp, fit many new Gaussian processes with new initial estimates for the hyperparameters. The  initial estimates are chosen based on provided ranges for the hyperparameters and Latin hypercube sampling. See also fit_GP.\n\nArguments\n\ngp: A Gaussian process object, fitted uses the GaussianProcesses.jl package. \nℓₓ: A 2-vector giving the lower and upper bounds for the initial estimates of ℓₓ (defined on a log scale).\nℓₜ: A 2-vector giving the lower and upper bounds for the initial estimates of ℓₜ (defined on a log scale).\nσ: A 2-vector giving the lower and upper bounds for the initial estimates of σ (defined on a log scale).\nσₙ: A 2-vector giving the lower and upper bounds for the initial estimates of σₙ (defined on a log scale).\n\nKeyword Arguments\n\nnum_restarts = 50: The number of restarts to perform.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.precompute_gp_mean-Tuple{Any, Any, Any, Any, Any, Any, Any, Any, Any, Bootstrap_Setup}","page":"Index","title":"EquationLearning.precompute_gp_mean","text":"precompute_gp_mean(x, t, u, ℓₓ, ℓₜ, σ, σₙ, nugget, num_restarts, bootstrap_setup::Bootstrap_Setup)\n\nComputes the Gaussian process and corresponding mean vector and Cholesky factor for a  joint Gaussian process defined by the data (x, t, u). See also  compute_joint_GP and bootstrap_gp.\n\nArguments\n\nx: The spatial data. \nt: The temporal data.\nu: The targets corresponding to (x, t).\nℓₓ: A 2-vector giving the lower and upper bounds for the initial estimates of ℓₓ (defined on a log scale).\nℓₜ: A 2-vector giving the lower and upper bounds for the initial estimates of ℓₜ (defined on a log scale).\nσ: A 2-vector giving the lower and upper bounds for the initial estimates of σ (defined on a log scale).\nσₙ: A 2-vector giving the lower and upper bounds for the initial estimates of σₙ (defined on a log scale).\nnugget: The term to add to the diagonals of the covariance matrix in case the matrix is not positive definite.\nnum_restarts = 50: Number of times to restart the optimiser. See opt_restart!.\nbootstrap_setup::Bootstrap_Setup: A Bootstrap_Setup struct for defining the bootstrapping grid.\n\nOutputs\n\ngp_setup: The fitted Gaussian process.\nμ: The mean vector for the joint Gaussian proces.\nL: The Cholesky factor for the joint Gaussian process.\n\n`\n\n\n\n\n\n","category":"method"},{"location":"index.html#optimisation.jl","page":"Index","title":"optimisation.jl","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"Modules = [EquationLearning]\nPages = [\"optimisation.jl\"]","category":"page"},{"location":"index.html#EquationLearning.check_constraints-Tuple{Any, Any}","page":"Index","title":"EquationLearning.check_constraints","text":"check_constraints(Tval, Dval)\n\nChecks if Tval < 0.0 or if Dval < 0.0. If either of these conditions are true, returns true; otherwise false.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.check_constraints-Tuple{Any, Function, Function, Function, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any}","page":"Index","title":"EquationLearning.check_constraints","text":"check_constraints(αβγ, T::Function, D::Function, R::Function, α, β, γ, T_params, D_params, R_params, \n    finalTime, maxf, glnodes, glweights, RuN, uvals, tvals)\n\nChecks if the current parameter values violate the constraints D > 0, T > 0, ∫R > 0.\n\nArguments\n\nαβγ: The parameter values for the delay, diffusion, and reaction terms, given in the form [α, β, γ].\nT::Function: The delay function, given in the form T(t, α...).\nD::Function: The diffusion function, given in the form D(u, β...).\nR::Function: The reaction function, given in the form R(u, γ...).\nα: Initial estimates for the delay parameters.\nβ: Initial estimates for the diffusion parameters. \nγ: Initial estimates for the reaction parameters.\nT_params: Additional known parameters for the delay function.\nD_params: Additional known parameters for the diffusion function.\nR_params: Additional known parameters for the reaction function. \nfinalTime: The final time to give the solution to the PDE at.\nmaxf: The maximum value of f.\nglnodes: Gauss-Legendre quadrature nodes.\nglweights: Gauss-Legendre quadrature weights.\nRuN: For storing values of the reaction function at Gauss-Legendre quadrature nodes.\nuvals: Values for u used for testing constraints. \ntvals: Values for t used for testing constraints.\n\nOutput\n\ntrue is any of the constraints are violated, and false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.learn_equations!-Tuple{Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Vararg{Any}}","page":"Index","title":"EquationLearning.learn_equations!","text":"learn_equations!(<arguments>)\n\nEstimate values for the delay, diffusion, and reaction parameters. See bootstrap_gp and loss_function.\n\nArguments\n\nx: The spatial data.\nt: The temporal data.\nu: The density data.\nf: Computed values of f(x, t).\nfₜ: Computed values of fₜ(x, t).\nfₓ: Computed values of fₓ(x, t).\nfₓₓ: Computed values of fₓₓ(x, t).\nT::Function: The delay function, given in the form T(t, α., ).\nD::Function: The diffusion function, given in the form D(u, β...).\nD′::Function: The derivative of the diffusion function, given in the form D′(u, β...).\nR::Function: The reaction function, given in the form R(u, γ...).\nR′::Function: The derivative of the reaction function, given in the form R′(u, γ, R_params).\nT_params: Additional known parameters for the delay function.\nD_params: Additional known parameters for the diffusion function.\nR_params: Additional known parameters for the reaction function. \nα: Initial estimates for the delay parameters.\nβ: Initial estimates for the diffusion parameters. \nγ: Initial estimates for the reaction parameters.\nstacked_params: Matrix which stores parameter values at each optimisation restart. The columns take the form [α₀; β₀; γ₀].\nlowers: Lower bounds to use for constructing the Latin hypersquare design, and for the constrained problem if bootstrap_setup.constrained = true.\nuppers: Upper bounds to use for constructing the Latin hypersquare design, and for the constrained problem if bootstrap_setup.constrained = true.\nconstrained: true if the optimisation problems should be constrained, and false otherwise.\nobj_values: Cache array for storing the objective function values at each optimisation restart.\nobj_scale_GLS: The amount by which the GLS loss function should be scaled.\nobj_scale_PDE: The amount by which the PDE loss function should be scaled.\nN: The number points.\nV: The volume of each cell in the spatial mesh.\nΔx: The spacing between each point in the spatial mesh.\nLHS: Vector defining the left-hand boundary conditions for the PDE. See also the definitions of (a₀, b₀, c₀) in sysdegeneral!.\nRHS: Vector defining the right-hand boundary conditions for the PDE. See also the definitions of (a₁, b₁, c₁) in sysdegeneral!.\ninitialCondition: The initial condition to use for the PDE.\nfinalTime: The final time to give the solution to the PDE at.\nalg: The algorithm to use for solving the discretised PDE.\nδt: A vector specifying the times to return the solution to the discretised PDE at.\nSSEArray: Cache array for storing the solutions to the PDE. \nDu: Cache array for storing the values of the diffusion function at the mesh points. Should be defined as a PreallocationTools.DiffCache type; see bootstrap_helper.\nRu: Cache array for storing the values of the reaction function at the mesh points.  Should be defined as a PreallocationTools.DiffCache type; see bootstrap_helper.\nD′u: Cache array used for storing the values of the derivative of the diffusion function D at D′(u).\nR′u: Cache array used for storing the values of the derivative of the reaction function R at R′(u).\nTuP: Cache array for storing the values of the delay function at the unscaled times (for the \"PDE\" loss function).  Should be defined as a PreallocationTools.DiffCache type; see bootstrap_helper.\nDuP: Cache array for storing the values of the diffusion function at the estimated density values (for the \"PDE\" loss function).  Should be defined as a PreallocationTools.DiffCache type; see bootstrap_helper.\nRuP: Cache array for storing the values of the reaction function at the estimated density values (for the \"PDE\" loss function).  Should be defined as a PreallocationTools.DiffCache type; see bootstrap_helper.\nD′uP: Cache array for storing the values of the derivative of the diffusion function at the estimated density values (for the \"PDE\" loss function).  Should be defined as a PreallocationTools.DiffCache type; see bootstrap_helper.\nRuN: For storing values of the reaction function at Gauss-Legendre quadrature nodes.  Should be defined as a PreallocationTools.DiffCache type; see bootstrap_helper.\ninIdx: Indices in f (and fₜ) that should be used in the optimisation process. See aso data_thresholder.\nunscaled_t̃: Unscaled t values for the bootstrapping grid. \ntt: Number of delay parameters.\nd: Number of diffusion parameters.\nr: Number of reaction reaction parameters.\nerrs: Cache array for storing the individual error values. Should be defined as a PreallocationTools.DiffCache type.\nMSE: Cache array for storing the individual squared errors. Should be defined as a PreallocationTools.DiffCache type.\noptim_setup: An Optim.Options struct used for defining options in Optim.optimize.\niterate_idx: Indices to use on the data for finding indices corresponding to specific time values. See the definition in bootstrap_gp.\nclosest_idx: Points in the spatial mesh for the ODEs that are closest to the positions in the spatial data x. See the definition in bootstrap_gp.\nnodes: The Gauss-Legendre quadrature nodes.\nweights: The Gauss-Legendre quadrature weights.\nshow_losses: true if the loss function should be printed to the REPL throughout the optimisation process, and false otherwise.\nσₙ: The standard deviation of the observation noise, estimated from the Gaussian process.\ninit_weight: Weight factor for the initial condition for the GLS errors.\nuvals: Values for u used for testing constraints. \ntvals: Values for t used for testing constraints.\nPDEkwargs...: The keyword arguments to use in DifferentialEquations.solve.\n\nOutputs\n\nThe estimates for the delay parameters, α, diffusion parameters, β, and reaction parameters,  γ, are updated in-place.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.loss_function-Tuple{Any}","page":"Index","title":"EquationLearning.loss_function","text":"loss_function(αβγ; <keyword arguments>)\n\nComputes the loss function at αβγ.\n\nArguments\n\nαβγ: The parameter values for the delay, diffusion, and reaction terms, given in the form [α, β, γ].\n\nKeyword Arguments\n\nu: The density data used for fitting the Gaussian process. See fit_GP.\nf: Computed values of f(x, t).\nfₓ: Computed values of fₓ(x, t).\nfₓₓ: Computed values of fₓₓ(x, t).\nfₜ: Computed values of fₜ(x, t).\nN: Number of mesh points being used for solving the PDEs.\nV: The volume of each cell in the discretised PDE.\nΔx: The spacing between cells in the discretised PDE.\nLHS: Vector of the form [a₀, b₀, c₀] which specifies the boundary conditions. \nRHS: Vector of the form [a₁, b₁, c₁] which specifies the boundary conditions. \nT: The delay function, given in the form T(t, α...).\nD: The diffusion function, given in the form D(u, β...).\nD′: The derivative of the diffusion function, given in the form D′(u, β...).\nR: The reaction function, given in the form R(u, γ...).\nR′::Function: The derivative of the reaction function, given in the form R′(u, γ, R_params).\ninitialCondition: Vector for the initial condition for the PDE.\nfinalTime: The final time to give the solution to the PDE at.\nEQLalg: The algorithm to use for solving the PDE. Cannot be a Sundials algorithm.\nδt: A number or a vector specifying the spacing between returned times for the solutions to the PDEs or specific times, respectively.\nSSEArray: Cache array for storing the solutions to the PDE. \nDu: Cache array for storing the values of the diffusion function at the mesh points.\nRu: Cache array for storing the values of the reaction function at the mesh points. \nD′u: Cache array used for storing the values of the derivative of the diffusion function D at D′(u).\nR′u: Cache array used for storing the values of the derivative of the reaction function R at R′(u).\nTuP: Cache array for storing the values of the delay function at the unscaled times (for the \"GLS\" loss function).\nDuP: Cache array for storing the values of the diffusion function at the estimated density values (for the \"GLS\" loss function).\nRuP: Cache array for storing the values of the reaction function at the estimated density values (for the \"GLS\" loss function).\nD′uP: Cache array for storing the values of the derivative of the diffusion function at the estimated density values (for the \"GLS\" loss function).\nRuN: For storing values of the reaction function at Gauss-Legendre quadrature nodes.\ninIdx: The indices for the data to use. See data_thresholder.\nunscaled_t̃: The unscaled time values on the bootstrapping grid.\ntt: The number of delay parameters.\nd: The number of diffusion parameters.\nr: The number of reaction parameters.\nerrs: Cache array for storing the individual error values.\nMSE: Cache array for storing the individual squared errors.\nobj_scale_GLS: Scale to divide the GLS loss by.\nobj_scale_PDE: Scale to divide the PDE loss by.\nglnodes: Gauss-Legendre quadrature nodes.\nglweights: Gauss-Legendre quadrature weights.\nmaxf: The maximum value of f.\nD_params: Extra parameters for the diffusion function.\nR_params: Extra parameters for the reaction function. \nT_params: Extra parameters for the delay function.\niterate_idx: Vector used for indexing the values in u corresponding to different times.\nclosest_idx: Vector used for indexing the points in the PDE's meshpoints that are closest to the actual spatial data used for fitting the Gaussian process.\nshow_losses: Whether to print the individual loss functions to the REPL during the optimisation process.\nσₙ: The standard deviation of the observation noise of the Gaussian process.\ninit_weight: Weight factor for the initial condition for the GLS errors.\nuvals: Values for u used for testing constraints. \ntvals: Values for t used for testing constraints.\nPDEkwargs...: The keyword arguments to use in DifferentialEquations.solve.\n\nExtended help\n\nThere are two types of loss functions currently considered, namely \"GLS\" and \"PDE\". For \"PDE\", the loss function is \n\nfrac1n_xn_tsum_i=1^n_xsum_j=1^n_tleftfracpartial u_ijpartial t - T(t_j mathbfalpha)leftfracmathrmdD(u_ij mathbfbeta)mathrm duleft(fracpartial u_ijxright)^2 + D(u_ij mathbfbeta)fracpartial^2u_ijpartial x^2 + R(u_ij mathbfgamma)rightright\n\nFor \"GLS\", the loss function is (see Lagergren et al. (2020): https://doi.org/10.1098/rspa.2019.0800)\n\nfrac1NMsum_i=1^Nsum_j=1^M left(frachat u_ij - u_ijσ_nright)^2,\n\nIf the ODE solver returns an error for the given parameter values, ∞ is added to the loss function as a penalty.\n\n\n\n\n\n","category":"method"},{"location":"index.html#pdes.jl","page":"Index","title":"pdes.jl","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"Modules = [EquationLearning]\nPages = [\"pdes.jl\"]","category":"page"},{"location":"index.html#EquationLearning.boot_pde_solve-Tuple{BootResults, Any, Any, Any}","page":"Index","title":"EquationLearning.boot_pde_solve","text":"boot_pde_solve(bgp::BootResults, x_pde, t_pde, u_pde; prop_samples = 1.0, ICType = \"data\")\n\nSolve the PDEs corresponding to the bootstrap iterates in bgp obtained from bootstrap_gp. \n\nArguments\n\nbgp::BootResults: A BootResults struct containing the results from bootstrap_gp.\nx_pde: The spatial data to use for obtaining the initial condition.\nt_pde: The temporal data to use for obtaining the initial condition.\nu_pde: The density data to use for obtaining the initial condition.\n\nKeyword Arguments\n\nprop_samples = 1.0: The proportion of bootstrap samples to compute the corresponding PDE soluton to.\nICType = \"data\": The type of initial condition to use. Should be either \"data\" or \"gp\".\n\nOutputs\n\nsolns_all: The solutions to the PDEs over the mesh points at each time value.\n\nNote\n\nThe _pde subscript is used to indicate that these data need not be the same as the (x, t, u) used in bootstrap_gp, for example. For example, we may have 3 replicates of some data which we would easily use in bootstrap_gp, but for the PDE we would need to average these  together for obtaining the solutions.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.compute_initial_conditions-Tuple{Any, Any, Any, Any, Union{BasisBootResults, BootResults}, Any, Any, Any}","page":"Index","title":"EquationLearning.compute_initial_conditions","text":"compute_initial_conditions(x_pde, t_pde, u_pde, ICType, bgp::Union{BootResults, BasisBootResults}, N, B, meshPoints)\n\nComputes initial conditions for the bootstrap iterates in bgp. See also bootstrap_gp.\n\nArguments\n\nx_pde: The spatial data used for fitting the original Gaussian process. See also fit_GP.\nt_pde: The temporal data used for fitting the original Gaussian process. See also fit_GP.\nu_pde: The density data used for fitting the original Gaussian process. See also fit_GP.\nICType: The type of initial condition to use. If ICType == \"data\" then the initial condition is simply a spline through the data, and if ICType == \"gp\" then the initial condition is a sample of the underlying Gaussian process in bgp.gp.\nbgp::Union{BootResults, BasisBootResults}: The bootstrapping results.\nN: The number of mesh points.\nB: The number of bootstrap iterations.\nmeshPoints: The spatial mesh.\n\nOutputs\n\ninitialCondition_all: The initial condition to use for each bootstrap iterate, with the jth column corresponding to the jth bootstrap sample.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.compute_initial_conditions-Tuple{Any, Any, Any, Union{BasisBootResults, BootResults}, Any}","page":"Index","title":"EquationLearning.compute_initial_conditions","text":"compute_initial_conditions(x_pde, t_pde, u_pde, bgp::Union{BootResults, BasisBootResults})\n\nMethod for calling [compute_initial_conditions] when providing only bgp and the data. \n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.compute_valid_pde_indices-Tuple{Any, Any, Any, Any, Any, BootResults}","page":"Index","title":"EquationLearning.compute_valid_pde_indices","text":"compute_valid_pde_indices(u_pde, num_t, num_u, nodes, weights, bgp::BootResults)\n\nMethod for calling [compute_valid_pde_indices] when providing only bgp and the data. \n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.compute_valid_pde_indices-Tuple{BootResults, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any}","page":"Index","title":"EquationLearning.compute_valid_pde_indices","text":"compute_valid_pde_indices(bgp, u_pde, num_t, num_u, B, tr, dr, rr, nodes, weights, D_params, R_params, T_params)\n\nComputes the indices corresponding to the bootstrap samples which give valid PDE solutions. The check is done by  ensuring that the delay and diffusion values are strictly nonnegative, and the area under the reaction curve is nonnegative.\n\nArguments\n\nbgp::BootResults: The bootstrapping results of type BootResults. See bootstrap_gp.\nu_pde: The density data used for fitting the original Gaussian process. See also fit_GP.\nnum_t: The number of time values to use for checking the validity of the delay function values. \nnum_u: The number of density values to use for checking the validity of the diffusion function values.\nB: The number of bootstrap samples used.\ntr: The matrix of estimated delay parameters. \ndr: The matrix of estimated diffusion parameters.\nrr: The matrix of estimated reaction parameters.\nnodes: Gauss-Legendre quadrature nodes.\nweights: Gauss-Legendre quadrature weights.\nD_params: Extra parameters for the diffusion function.\nR_params: Extra parameters for the reaction function. \nT_params: Extra parameters for the delay function.\n\nOutputs\n\nidx: The vector of indices corresponding to valid bootstrap samples.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.error_comp-NTuple{5, Any}","page":"Index","title":"EquationLearning.error_comp","text":"error_comp(bgp, solns_all, x, t, u; level = 0.05)\n\nComputes the error between solutions to a PDE compared to data (x, t, u) from the bootstrapping procedure. The error measure used is median(100 * (absolute errors) / max(eps(Float64), u)).\n\nArguments\n\nbgp: Bootstrapping results.\nsolns_all: PDE solutions.\nx: Spatial data.\nt: Temporal data.\nu: Density data.\n\nKeyword Arguments\n\nlevel = 0.05: Level for the confidence interval.\ncompute_mean = false: Whether to only report the mean.\n\nOutputs\n\nerr_CI: 100(1-level)% confidence interval for the error.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.sysdegeneral!-NTuple{4, Any}","page":"Index","title":"EquationLearning.sysdegeneral!","text":"sysdegeneral!(dudt, u, p, t)\n\nFunction for computing the system of ODEs used in a discretised delay-reaction-diffusion PDE.\n\nArguments\n\ndudt: A cache array used for storing the left-hand side of the system of ODEs. \nu: The current values for the variables in the systems.\np: A tuple of parameters, given by:\np[1] = N: Number of mesh points being used for solving the PDE.\np[2] = V: The volume of each cell in the discretised PDE.\np[3] = h: The spacing between cells in the discretised PDE.\np[4] = a₀: The coefficient on u(a, t) in the Robin boundary condition at x = a (the left end-point of the mesh). \np[5] = b₀: The coefficient on -∂u(a, t)/∂x in the Robin boundary condition at x = a (the left end-point of the mesh).\np[6] = c₀: The right-hand side constant in the Robin boundary condition at x = a (the left end-point of the mesh).\np[7] = a₁: The coefficient on u(b, t) in the Robin boundary condition at x = b (the right end-point of the mesh). \np[8] = b₁: The coefficient on ∂u(b, t)/∂t in the Robin boundary condition at x = b (the right end-point of the mesh).\np[9] = c₁: The right-hand side constant in the Robin boundary condition at x = b (the right end-point of the mesh).\np[10] = DD: Cache array used for storing the values of the diffusion function D at D(u).\np[11] = RR: Cache array used for storing the values of the reaction function R at R(u).\np[12] = DD′: Cache array used for storing the values of the derivative of the diffusion function D at D′(u).\np[13] = RR′: Cache array used for storing the values of the derivative of the reaction function R at R′(u).\np[14] = T: The delay function, given in the form T(t, α, T_params).\np[15] = D: The diffusion function, given in the form D(u, β, D_params).\np[16] = R: The reaction function, given in the form R(u, γ, R_params).\np[17] = D′: The derivative of the diffusion function, given in the form D′(u, β, D_params).\np[18] = R′: The derivative of the reaction function, given in the form R′(u, γ, R_params).\np[19] = tb: The values of the delay parameters.\np[20] = db: The values of the diffusion parameters.\np[21] = rb: The values of the reaction parameters.\np[22] = D_params: Extra parameters used in the diffusion function.\np[23] = R_params: Extra parameters for the reaction function.\np[24] = T_params: Extra parameters for the delay function.\nt: The current time value.\n\nOutputs\n\nThe values are updated in-place into the vector dudt for the new value of dudt at time t.\n\n\n\n\n\n","category":"method"},{"location":"index.html#plot_results.jl","page":"Index","title":"plot_results.jl","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"Modules = [EquationLearning]\nPages = [\"plot_results.jl\"]","category":"page"},{"location":"index.html#EquationLearning.curve_results-Tuple{BootResults}","page":"Index","title":"EquationLearning.curve_results","text":"curve_results(bgp::BootResults; <keyword arguments>)\n\nPlots the learned functional forms along with confidence intervals for the bootstrapping results in bgp.\n\nArguments\n\nbgp: A BootResults object which contains the results for the bootstrapping. \n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nfontsize = 23: Font size for the plots (to be used in plot_aes!).\nx_scale = 1.0: Value used for scaling the spatial data (and all other length units, e.g. for diffusion).\nt_scale = 1.0: Value used for scaling the temporal data (and all other time units, e.g. for reaction).\n\nOutputs\n\ndelayCurvePlots: A plot containing the learned functional form for the delay function, along with an uncertainty ribbon.\ndiffusionCurvePlots: A plot containing the learned functional form for the diffusion function, along with an uncertainty ribbon.\nreactionCurvePlots: A plot containing the learned functional form for the reaction function, along with an uncertainty ribbon.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.curve_values-Tuple{BootResults}","page":"Index","title":"EquationLearning.curve_values","text":"curve_values(bgp::BootResults; <keyword arguments>)\n\nComputes values for plotting the learned functional forms along with confidence intervals for the bootstrapping results in bgp.\n\nArguments\n\nbgp: A BootResults object which contains the results for the bootstrapping. \n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nx_scale = 1.0: Value used for scaling the spatial data (and all other length units, e.g. for diffusion).\nt_scale = 1.0: Value used for scaling the temporal data (and all other time units, e.g. for reaction).\n\nOutputs\n\nTu_vals: Ribbon features for the delay functions. \nDu_vals: Ribbon features for the diffusion functions.\nRu_vals: Ribbon features for the reaction functions.\nu_vals: The density values used for computing the functions. \nt_vals: The time values used for computing the functions.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.delay_product-Tuple{Any, Any}","page":"Index","title":"EquationLearning.delay_product","text":"delay_product(bgp, t; type = \"diffusion\", level = 0.05, x_scale = 1.0, t_scale = 1.0)\n\nComputes the curve T(t; α)D(u; β) (if type = \"diffusion\") or T(t; β)R(u; γ) (if type = \"reaction\") with uncertainty for the results in bgp, at the time t. The significance level is determined by level (0.05 default) and the spatial and temporal data are scaled by x_scale (1.0 default) and t_scale (1.0 default), respectively.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.density_results-Tuple{BootResults}","page":"Index","title":"EquationLearning.density_results","text":"density_results(bgp::BootResults; <keyword arguments>)\n\nPlots the densities for the bootstrapping results in bgp.\n\nArguments\n\nbgp: A BootResults object which contains the results for the bootstrapping. \n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nfontsize = 23: Font size for the plots (to be used in plot_aes!).\ndelay_scales = nothing: Values that multiply the individual delay parameters.\ndiffusion_scales = nothing: Values that multiply the individual diffusion parameters. \nreaction_scales = nothing: Values that multiply the individual reaction parameters.\ndiffusion_resolution = (800, 800): Resolution for the diffusion figure.\nreaction_resolution = (800, 800): Resolution for the reaction figure.\ndelay_resolution = (800, 800): Resolution for the delay fgure.\n\nOutputs\n\ndelayDensityFigure: A figure of plots containing a density plot for each delay parameter.\ndiffusionDensityFigure: A figure of plots containing a density plot for each diffusion parameter.\nreactionDensityFigure: A figure of plots containing a density plot for each reaction parameter.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.density_values-Tuple{BootResults}","page":"Index","title":"EquationLearning.density_values","text":"density_values(bgp::BootResults; <keyword arguments>)\n\nComputes the densities for the bootstrapping results in bgp.\n\nArguments\n\nbgp: A BootResults object which contains the results for the bootstrapping. \n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nfontsize = 23: Font size for the plots (to be used in plot_aes!).\ndelay_scales = nothing: Values that multiply the individual delay parameters.\ndiffusion_scales = nothing: Values that multiply the individual diffusion parameters. \nreaction_scales = nothing: Values that multiply the individual reaction parameters.\n\nOutputs\n\ntrv: Delay densities.\ndr: Diffusion densities. \nrr: Reaction densities. \ntt: Number of delay parameters.\nd: Number of diffusion parameters.\nr: Number of reaction parameters. \ndelayCIs: Confidence intervals for the delay parameters. \ndiffusionCIs: Confidence intervals for the diffusion parameters. \nreactionCIS: Confidence intervals for the reaction parameters.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.pde_results-Tuple{Any, Any, Any, Any, Union{BasisBootResults, BootResults}}","page":"Index","title":"EquationLearning.pde_results","text":"pde_results(x_pde, t_pde u_pde, solns_all, bgp::Union{BootResults, BasisBootResults}; <keyword arguments>)\n\nPlots the solutions to the PDEs corresponding to the bootstrap samples of bootstrap_gp using  the computed solutins in boot_pde_solve.\n\nArguments\n\nx_pde: The spatial data to plot as points.\nt_pde: The temporal data to plot as points.\nu_pde: The density data to plot as points. \nsolns_all: The solutions to the PDEs for each bootstrap iteration. \nbgp::Union{BootResults, BasisBootResults}: A BootResults or BasisBootResults struct containing the results from bootstrap_gp or basis_bootstrap_gp, respectively.\n\nKeyword Arguments\n\ncolors = [:black, :blue, :red, :magenta, :green]: A list of colors for colouring the solutions at each time.\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nfontsize = 23: Font size for the plots (to be used in plot_aes!).\nx_scale = 1.0: Value used for scaling the spatial data (and all other length units, e.g. for diffusion).\nt_scale = 1.0: Value used for scaling the temporal data (and all other time units, e.g. for reaction).`\n\nOutputs\n\npdeSolutionPlots_BGP: The plot of the PDE solutions.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.pde_values-Tuple{Any, Union{BasisBootResults, BootResults}}","page":"Index","title":"EquationLearning.pde_values","text":"function pde_values(solns_all, bgp::Union{BootResults, BasisBootResults}; level = 0.05)\n\nPlots the solutions to the PDEs corresponding to the bootstrap samples of bootstrap_gp using  the computed solutins in boot_pde_solve.\n\nArguments\n\nsolns_all: The solutions to the PDEs for each bootstrap iteration. \nbgp::Union{BootResults, BasisBootResults}: Bootstrapping results.\n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \n\nOutputs\n\nsoln_vals_mean: Mean solution values. \nsoln_vals_lowers: Lower confidence interval for solution values.\nsoln_vals_upper: Upper confidence interval for solution values.\n\n\n\n\n\n","category":"method"},{"location":"index.html#synthetic_data.jl","page":"Index","title":"synthetic_data.jl","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"Modules = [EquationLearning]\nPages = [\"synthetic_data.jl\"]","category":"page"},{"location":"index.html#EquationLearning.generate_data-NTuple{12, Any}","page":"Index","title":"EquationLearning.generate_data","text":"generate_data(x₀, u₀, T, D, R, α, β, γ, δt, finalTime; <keyword arguments>)\n\nGenerate synthetic data from values (x₀, t₀) at t = 0 with exact mechanisms T, D, and R for delay, diffusion, and reaction, respectively. \n\nArguments\n\nx₀: The spatial mesh for points at t = 0.\nu₀: The density values at t = 0 corresponding to the points in x₀.\nT: A delay function of the form T(t, α, T_params).\nD: A diffusion function of the form D(u, β, D_params).\nR: A reaction function of the form R(u, γ, R_params).\nD′: The derivative of the diffusion function, given in the form D′(u, β, D_params).\nR′: The reaction function, given in the form R(u, γ, R_params).\nα: Exact values for the delay parameters.\nβ: Exact values for the diffusion parameters.\nγ: Exact values for the reaction parameters. \nδt: Times to save the solution to the differential equations at for generating the data.\nfinalTime: The time to solve the differential equations up to.\n\nKeyword Arguments\n\nN = 1000: The number of mesh points to use.\nLHS = [0.0, 1.0, 0.0]: Vector defining the left-hand boundary conditions for the PDE. See also the definitions of (a₀, b₀, c₀) in sysdegeneral!.\nRHS = [0.0, -1.0, 0.0]: Vector defining the right-hand boundary conditions for the PDE. See also the definitions of (a₁, b₁, c₁) in sysdegeneral!.\nalg = nothing: The algorithm to use for solving the differential equations.\nN_thin = 100: The number of points to take from the solution at each time.\nnum_restarts = 50: The number of times to restart the optimiser for fitting the Gaussian process to the data.\nD_params: Additional known parameters for the diffusion function.\nR_params: Additional known parameters for the reaction function.\nT_params: Additional known parameters for the delay function.\n\n\n\n\n\n","category":"method"},{"location":"index.html#utils.jl","page":"Index","title":"utils.jl","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"Modules = [EquationLearning]\nPages = [\"utils.jl\"]","category":"page"},{"location":"index.html#EquationLearning.compute_ribbon_features-Tuple{Any}","page":"Index","title":"EquationLearning.compute_ribbon_features","text":"compute_ribbon_features(x; level = 0.05)\n\nComputes features for a confidence interval plot for some data x.\n\nArguments\n\nx: The data to use for plotting.\n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \n\nOutputs\n\nx_mean: The mean of each row of x.\nx_lower: The 100(level/2)% quantile for each row of x.\nx_upper: The 100(1-level/2)% quantile for each row of x.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.data_thresholder-Tuple{Any, Any, Any}","page":"Index","title":"EquationLearning.data_thresholder","text":"data_thresholder(f, fₜ, τ)\n\nThresholds the data given by f with temporal derivatives fₜ based on a threshold tolerance τ. The returned values  in inIdx give the indices in f (and fₜ) that should be kept. \n\nArguments\n\nf: Computed values of f(x, t).\nfₜ: Computed values of fₜ(x, t).\nτ: A tuple of the form (τ₁, τ₂) which gives the tolerance τ₁ for thresholding f and τ₂ for thresholding fₜ.\n\nOutputs\n\ninIdx: Indices in f (and fₜ) that should be kept.\n\nExtended help\n\nThe threshold conditions are:\n\n1. `min(|f|)τ₁ ≤ |f| ≤ max(|f|)(1-τ₁)`.\n2. `min(|fₜ|)τ₂ ≤ |fₜ| ≤ max(|fₜ|)(1-τ₂2)`.\n3. `f ≥ 0.0`.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.scale_unit-Tuple{Any}","page":"Index","title":"EquationLearning.scale_unit","text":"scale_unit(x)\n\nScales the data in x such that x ∈ [0, 1].\n\nArguments\n\nx: The data to be scaled. \n\nOutputs\n\nxx: The scaled data such that xx ∈ [0, 1].\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.searchsortednearest-Tuple{Any, Any}","page":"Index","title":"EquationLearning.searchsortednearest","text":"searchsortednearest(a, x; <keyword arguments>)\n\nFinds the index in a that has the smallest distance to x. Ties go to the smallest index.\n\nSource: Taken from https://github.com/joshday/SearchSortedNearest.jl/blob/main/src/SearchSortedNearest.jl.\n\nArguments\n\na: A sorted collection.\nx: A value which is used for comparing the values of a to for finding the closest value.\n\nKeyword Arguments\n\nby = identity: The order in which a is sorted. If a is sorted, this is just identity.\nlt = isless: The metric used for sorting values in a, typically lt = isless which uses <.\nrev = false: Whether to reverse the array a.\ndistance = (a, b) -> abs(a - b): The distance metric used for assessing which value is closest.\n\nOutputs\n\ni: The index such that distance(a[i], a) is minimised.\n\n\n\n\n\n","category":"method"},{"location":"index.html#EquationLearning.update_results-Tuple{Any, Any, Any}","page":"Index","title":"EquationLearning.update_results","text":"update_results(bgp, bgp_new, mechanism)\n\nUpdates the results in bgp with new results bgp_new for a re-estimated mechanism.\n\n\n\n\n\n","category":"method"},{"location":"index.html#Links","page":"Index","title":"Links","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"Modules = [EquationLearning]","category":"page"},{"location":"ref.html#Manual","page":"Manual","title":"Manual","text":"","category":"section"},{"location":"ref.html","page":"Manual","title":"Manual","text":"This section lists some of the docstrings for the functions defined from our module. All functions in this package are documented, though we only the important ones that are likely to be used by a user here. The remaining docstrings in this package are listed in the index section.","category":"page"},{"location":"ref.html#Structs","page":"Manual","title":"Structs","text":"","category":"section"},{"location":"ref.html","page":"Manual","title":"Manual","text":"GP_Setup\nBootstrap_Setup\nPDE_Setup\nBootResults\nBasisBootResults\nAllResults","category":"page"},{"location":"ref.html#EquationLearning.GP_Setup","page":"Manual","title":"EquationLearning.GP_Setup","text":"GP_Setup\n\nSetup for the Gaussian processes. See also fit_GP and bootstrap_gp.\n\nFields\n\nℓₓ::Vector{Float64}: A 2-vector giving the lower and upper bounds for the initial estimates of ℓₓ (defined on a log scale).\nℓₜ::Vector{Float64}: A 2-vector giving the lower and upper bounds for the initial estimates of ℓₜ (defined on a log scale).\nσ::Vector{Float64}: A 2-vector giving the lower and upper bounds for the initial estimates of σ (defined on a log scale).\nσₙ::Vector{Float64}: A 2-vector giving the lower and upper bounds for the initial estimates of σₙ (defined on a log scale).\nGP_Restarts::Int: Number of times to restart the optimiser. See opt_restart!.\nμ::Union{Missing, Vector{Float64}}: Either Nothing or a stored mean vector for the Gaussian process. \nL::Union{Missing, LowerTriangular{Float64}}: Either Nothing or a stored Cholesky factor for the Gaussian process.\nnugget::Float64: Nugget term to add to the covariance matrix to be symmetric positive definite. This nugget is adapted to the blocks of the matrix based on the derivatives, as described in our paper.\ngp::Union{Missing, GPBase}: Either Nothing or a stored Gaussian process. See also fit_GP.\n\n\n\n\n\n","category":"type"},{"location":"ref.html#EquationLearning.Bootstrap_Setup","page":"Manual","title":"EquationLearning.Bootstrap_Setup","text":"struct Bootstrap_Setup\n\nA struct defining some arguments for bootstrap_gp.\n\nFields\n\nbootₓ::AbstractVector: The spatial grid for bootstrapping.\nbootₜ::AbstractVector: The temporal grid for bootstrapping.\nB::Int: Number of bootstrap samples.\nτ::Tuple{Float64, Float64}: A tuple of the form (τ₁, τ₂) which gives the tolerance τ₁ for thresholding f and τ₂ for thresholding fₜ. See also data_thresholder.\nOptim_Restarts::Int: Number of times to restart the optimiser for the nonlinear least squares problem. See also learn_equations!.\nconstrained::Bool: true if the optimisation problems should be constrained, and false otherwise.\nobj_scale_GLS::Function: The function determining how the GLS loss function should be scaled.\nobj_scale_PDE::Function: The function determining how the PDE loss function should be scaled.\ninit_weight::Float64: Weight factor for the initial condition for the GLS errors.\nshow_losses::Bool: true if the loss function should be printed to the REPL throughout the optimisation process, and false otherwise.\n\n\n\n\n\n","category":"type"},{"location":"ref.html#EquationLearning.PDE_Setup","page":"Manual","title":"EquationLearning.PDE_Setup","text":"struct PDE_Setup\n\nA struct defining some arguments for the PDEs in bootstrap_gp and boot_pde_solve.\n\nFields\n\nmeshPoints::AbstractVector: The spatial mesh to use for solving the PDEs involved when computing the \"GLS\" loss function, or for the PDEs in general.\nLHS::Vector{Float64}: Vector defining the left-hand boundary conditions for the PDE. See also the definitions of (a₀, b₀, c₀) in sysdegeneral!.\nRHS::Vector{Float64}: Vector defining the right-hand boundary conditions for the PDE. See also the definitions of (a₁, b₁, c₁) in sysdegeneral!.\nfinalTime::Float64: The final time to solve the PDE up to.\nδt::Union{AbstractVector, Float64}: A number or a vector specifying the spacing between returned times for the solutions to the PDEs or specific times, respectively.\nalg: Algorithm to use for solving the PDEs. If you want to let DifferentialEquations.jl select the algorithm automatically, specify alg = nothing. If automatic differentiation is being used in the ODE algorithm, then no Sundials algorithms can be used.\n\n\n\n\n\n","category":"type"},{"location":"ref.html#EquationLearning.BootResults","page":"Manual","title":"EquationLearning.BootResults","text":"struct BootResults\n\nStructure for storing bootstrapping results. See bootstrap_gp.\n\nFields\n\ndelayBases: The estimated delay parameters. Each column corresponds to a single bootstrap iteration.\ndiffusionBases: The estimated diffusion parameters. Each column corresponds to a single bootstrap iteration.\nreactionBases: The estimated reaction parameters. Each column corresponds to a single bootstrap iteration.\ngp: The fitted Gaussian process. See fit_gp.\nzvals: The simulated normal variables from N(0, I) used for drawing from the Gaussian process gp. See draw_gp!.\nXₛ: The test matrix for the bootstrapping grid data, given in the scale [0, 1].\nXₛⁿ: The unscaled form of Xₛ.\nbootₓ: The spatial bootstrapping grid.\nbootₜ: The temporal bootstrapping grid.\nT: The delay function, given in the form T(t, α, T_params).\nD: The diffusion function, given in the form D(u, β, D_params).\nD′: The derivative of the diffusion function, given in the form D′(u, β, D_params).\nR: The reaction function, given in the form R(u, γ, R_params).\nR′: The derivative of the reaction function, given in the form R′(u, γ, R_params).\nD_params: Parameters for the diffusion function.\nR_params: Parameters for the reaction function. \nT_params: Parameters for the delay function.\ngp_setup: The GP setup used; see GP_Setup.\nbootstrap_setup: The bootstrap setup used; see bootstrap_setup.\npde_setup: The PDE setup used; see pde_setup.\n\n\n\n\n\n","category":"type"},{"location":"ref.html#EquationLearning.BasisBootResults","page":"Manual","title":"EquationLearning.BasisBootResults","text":"struct BasisBootResults\n\nStructure for storing bootstrapping results from the basis approach. See basis_bootstrap_gp.\n\nFields\n\ndiffusionBases: The estimated diffusion parameters. Each column corresponds to a single bootstrap iteration.\nreactionBases: The estimated reaction parameters. Each column corresponds to a single bootstrap iteration.\ngp: The fitted Gaussian process. See fit_gp.\nzvals: The simulated normal variables from N(0, I) used for drawing from the Gaussian process gp. See draw_gp!.\nXₛ: The test matrix for the bootstrapping grid data, given in the scale [0, 1].\nXₛⁿ: The unscaled form of Xₛ.\nbootₓ: The spatial bootstrapping grid.\nbootₜ: The temporal bootstrapping grid.\nD: The diffusion basis functions, each given in the form φ(u, D_params).\nD′: The derivative of the diffusion basis functions.\nR: The reaction basis function, each given in the form ψ(u, R_params).\nR′: The derivative of the reaction basis functions.\nD_params: Parameters for the diffusion function.\nR_params: Parameters for the reaction function. \ngp_setup: The GP setup used; see GP_Setup.\nbootstrap_setup: The bootstrap setup used; see bootstrap_setup.\npde_setup: The PDE setup used; see pde_setup.\n\n\n\n\n\n","category":"type"},{"location":"ref.html#EquationLearning.AllResults","page":"Manual","title":"EquationLearning.AllResults","text":"struct AllResults\n\nHelpful structure for displaying results. This differs from e.g. BootResults since we also include PDE solutions.\n\nFields\n\npde_solutions::Array{Float64}: Solutions for the PDEs with sampled initial conditions.\nAIC::Vector{Float64}: The AICs.\nbgp::Union{BootResults, BasisBootResults}: Bootstrapping results.\ndelayCIs: Confidence intervals for the delay parameters. \ndiffusionCIs: Confidence intervals for the diffusion parameters. \nreactionCIS: Confidence intervals for the reaction parameters.\ndelay_density::Figure: The density plots for the delay coefficients.\ndiffusion_density::Figure: The density plots for the diffusion coefficients.\nreaction_density::Figure: The density plots for the reaction coefficients.\ndelay_curve::Figure: Plot for the learned delay curve.\ndiffusion_curve::Figure: Plot for the learned diffusion curve.\nreaction_curve::Figure: Plot for the learned reaction curve.\npde_plot::Figure: Plot for the PDE solutions.\npde_error::Vector{Float64}: Confidence interval for the PDE errors.\n\n\n\n\n\n","category":"type"},{"location":"ref.html#Bootstrapping","page":"Manual","title":"Bootstrapping","text":"","category":"section"},{"location":"ref.html","page":"Manual","title":"Manual","text":"bootstrap_gp\nbasis_bootstrap_gp\nupdate_results","category":"page"},{"location":"ref.html#EquationLearning.bootstrap_gp","page":"Manual","title":"EquationLearning.bootstrap_gp","text":"bootstrap_gp(x::T1, t::T1, u::T1,\n    T::Function, D::Function, D′::Function, R::Function,\n    α₀::T1, β₀::T1, γ₀::T1, lowers::T1, uppers::T1;\n    gp_setup::GP_Setup = GP_Setup(u),\n    bootstrap_setup::Bootstrap_Setup = Bootstrap_Setup(x, t, u),\n    optim_setup::Optim.Options = Optim.Options(),\n    pde_setup::PDE_Setup = PDE_Setup(x),\n    D_params = nothing, R_params = nothing, T_params = nothing, zvals = nothing, PDEkwargs...) where {T1<:AbstractVector}\n\nPerform bootstrapping on the data (x, t, u) to learn the appropriate functional forms of  (T, D, R) with uncertainty. \n\nArguments\n\nx::T1: The spatial data.\nt::T1: The temporal data.\nu::T1: The density data.\nT::Function: The delay function, given in the formT(t, α, T_params)`.\nD::Function: The diffusion function, given in the form D(u, β, D_params).\nD′::Function: The derivative of the diffusion function, given in the form D′(u, β, D_params).\nR::Function: The reaction function, given in the form R(u, γ, R_params).\nR′::Function: The derivative of the reaction function, given in the form R′(u, γ, R_params).\nα₀::T1: Initial estimates of the delay parameters. Not actually used for anything other than ensuring the functions are specified correctly.\nβ₀::T1: Initial estimates of the diffusion parameters. Not actually used for anything other than ensuring the functions are specified correctly. \nγ₀::T1: Initial estimates of the reaction parameters. Not actually used for anything other than ensuring the functions are specified correctly. \nlowers::T1: Lower bounds to use for constructing the Latin hypersquare design, and for the constrained problem if constrained = true in bootstrap_setup.\nuppers::T1: Upper bounds to use for constructing the Latin hypersquare design, and for the constrained problem if constrained = true in bootstrap_setup.\n\nKeyword Arguments\n\ngp_setup::GP_Setup = GP_Setup(u): Defines the setup for the Gaussian process. See also GP_Setup.\nbootstart_setup::Bootstrap_Setup = Bootstrap_Setup(x, t, u): Defines some extra keyword arguments for the bootstrapping and optimisation process. See also Bootstrap_Setup.\noptim_setup::Optim.Options = Optim_Options(): Defines some options when using Optim.optimize.\npde_setup::PDE_Setup = PDE_Setup(x): Defines some extra keyword arguments for the PDE solutions. See also PDE_Setup.\nD_params = nothing: Extra known parameters for the diffusion function D.\nR_params = nothing: Extra known parameters for the reaction function R.\nT_params = nothing: Extra known parameters for the delay function T.\nPDEkwargs...: Extra keyword arguments to use inside DifferentialEquations.solve.\n\nOutputs\n\nbgp: A BootResults structure. See BootResults. \n\n\n\n\n\n","category":"function"},{"location":"ref.html#EquationLearning.basis_bootstrap_gp","page":"Manual","title":"EquationLearning.basis_bootstrap_gp","text":"basis_bootstrap_gp(x::T1, t::T1, u::T1,\n    D::Vector{Function}, D′::Vector{Function}, R::Vector{Function}, R′::Vector{Function};\n    gp_setup::GP_Setup = GP_Setup(u),\n    bootstrap_setup::Bootstrap_Setup = Bootstrap_Setup(x, t, u),\n    optim_setup::Optim.Options = Optim.Options(),\n    pde_setup::PDE_Setup = PDE_Setup(x),\n    D_params = nothing, R_params = nothing, PDEkwargs...) where {T1<:AbstractVector}\n\nPerform bootstrapping on the data (x, t, u) to learn the appropriate functional forms of  (T, D, R) with uncertainty, using the basis function approach.\n\nArguments\n\nx::T1: The spatial data.\nt::T1: The temporal data.\nu::T1: The density data.\nD::Vector{Function}: The diffusion function, given in the form D(u, β, D_params).\nD′::Vector{Function}: The derivative of the diffusion function, given in the form D′(u, β, D_params).\nR::Vector{Function}: The reaction function, given in the form R(u, γ, R_params).\nR′::Vector{Function}: The derivative of the reaction function, given in the form R′(u, γ, R_params).\n\nKeyword Arguments\n\ngp_setup::GP_Setup = GP_Setup(u): Defines the setup for the Gaussian process. See also GP_Setup.\nbootstart_setup::Bootstrap_Setup = Bootstrap_Setup(x, t, u): Defines some extra keyword arguments for the bootstrapping and optimisation process. See also Bootstrap_Setup.\npde_setup::PDE_Setup = PDE_Setup(x): Defines some extra keyword arguments for the PDE solutions. See also PDE_Setup.\nD_params = nothing: Extra known parameters for the diffusion function D.\nR_params = nothing: Extra known parameters for the reaction function R.\nPDEkwargs...: Extra keyword arguments to use inside DifferentialEquations.solve.\n\nOutputs\n\nbgp: A BasisBootResults structure. See BasisBootResults. \n\n\n\n\n\n","category":"function"},{"location":"ref.html#EquationLearning.update_results","page":"Manual","title":"EquationLearning.update_results","text":"update_results(bgp, bgp_new, mechanism)\n\nUpdates the results in bgp with new results bgp_new for a re-estimated mechanism.\n\n\n\n\n\n","category":"function"},{"location":"ref.html#Gaussian-Processes","page":"Manual","title":"Gaussian Processes","text":"","category":"section"},{"location":"ref.html","page":"Manual","title":"Manual","text":"fit_GP\ncompute_joint_GP\nprecompute_gp_mean","category":"page"},{"location":"ref.html#EquationLearning.fit_GP","page":"Manual","title":"EquationLearning.fit_GP","text":"fit_GP(x, t, u; <keyword arguments>)\n\nFits a Gaussian process with data (x, t) using the targets in u. \n\nArguments\n\nx: The spatial data. \nt: The temporal data.\nu: The targets corresponding to (x, t).\n\nKeyword Arguments\n\nℓₓ = log.([1e-4, 1.0]): A 2-vector giving the lower and upper bounds for the initial estimates of ℓₓ (defined on a log scale).\nℓₜ = log.([1e-4, 1.0]): A 2-vector giving the lower and upper bounds for the initial estimates of ℓₜ (defined on a log scale).\nσ = log.([1e-1, 2std(u)]): A 2-vector giving the lower and upper bounds for the initial estimates of σ (defined on a log scale).\nσₙ = log.([1e-5, 2std(u)]): A 2-vector giving the lower and upper bounds for the initial estimates of σₙ (defined on a log scale).\nnum_restarts = 50: Number of times to restart the optimiser. See opt_restart!.\n\nOutputs\n\ngp: The fitted Gaussian process.\n\n\n\n\n\nfit_GP(x, t, u, setup::GP_Setup)\n\nMethod for calling fit_GP with a setup defined by GP_Setup.\n\n\n\n\n\n","category":"function"},{"location":"ref.html#EquationLearning.compute_joint_GP","page":"Manual","title":"EquationLearning.compute_joint_GP","text":"compute_joint_GP(gp::GPBase, X̃; nugget = 1e-10)\n\nComputes the mean vector μ and Cholesky factor L such that LLᵀ = Σ, where \n\nleftbeginarrayc mathbff  fracpartialmathbf fpartial t  fracpartialmathbf fpartial x fracpartial^2mathbf fpartial x^2endarrayright sim mathcal Nleft(mathbfmu mathbfSigmaright)\n\nArguments\n\ngp::GPBase: The fitted Gaussian process. \nX̃: Test data for the Gaussian process. \n\nKeyword Arguments\n\nnugget = 1e-10: The term to add to the diagonals of the covariance matrix in case the matrix is not positive definite.\n\nOutputs\n\nμ: The mean vector. \nL: The Cholesky factor of the covariance matrix.\n\nExtended help\n\nThe covariance matrices are built without any attention to symmetry. The loops could be optimised by  e.g. considering only the upper triangular components. \n\nThe covariance matrices are built using separate functions for the derivatives of the kernel function (currently  only implemented for the squared exponential kernel). These functions are:\n\ndkxⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd²kxⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\ndktⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\ndktᵢ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd²ktᵢtⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd²ktᵢxⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd³tᵢxⱼ²(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\ndkxᵢ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd²kxᵢtⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd²kxᵢxⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd³kxᵢxⱼ²(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd²kxᵢ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd³kxᵢ²tⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd³kxᵢ²xⱼ(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\nd⁴kxᵢ²xⱼ²(x₁, t₁, x₂, t₂, ℓ₁, ℓ₂).\n\nIn these functions, the derivatives are evaluated at ([x₁; t₁], [x₂; t₂]) with length scales  (ℓ₁, ℓ₂) for space and time, respectively. The functions are missing a multiplication by the  kernel value cov(gp.kernel, [x₁; t₁], [x₂; t₂]) to allow for it to be done in place more easily.  Note also that in some of these functions, powers are written as products, e.g. x³ = x*x*x, to allow  for the @muladd macro to work (see https://github.com/SciML/MuladdMacro.jl). Since the functions are  quite small, we use @inline on each function to encourage the compiler to inline the function  in the LLVM.\n\nYou may get a StackOverflowError from this function. This may be related to https://github.com/JuliaLang/julia/issues/43242, in which case you can set the number of BLAS threads to 1:\n\njulia> ccall((:openblas_get_num_threads64_, Base.libblas_name), Cint, ()) # In case you need to remember how many threads you used prior\njulia> LinearAlgebra.BLAS.set_num_threads(1)\n\n\n\n\n\n","category":"function"},{"location":"ref.html#EquationLearning.precompute_gp_mean","page":"Manual","title":"EquationLearning.precompute_gp_mean","text":"precompute_gp_mean(x, t, u, ℓₓ, ℓₜ, σ, σₙ, nugget, num_restarts, bootstrap_setup::Bootstrap_Setup)\n\nComputes the Gaussian process and corresponding mean vector and Cholesky factor for a  joint Gaussian process defined by the data (x, t, u). See also  compute_joint_GP and bootstrap_gp.\n\nArguments\n\nx: The spatial data. \nt: The temporal data.\nu: The targets corresponding to (x, t).\nℓₓ: A 2-vector giving the lower and upper bounds for the initial estimates of ℓₓ (defined on a log scale).\nℓₜ: A 2-vector giving the lower and upper bounds for the initial estimates of ℓₜ (defined on a log scale).\nσ: A 2-vector giving the lower and upper bounds for the initial estimates of σ (defined on a log scale).\nσₙ: A 2-vector giving the lower and upper bounds for the initial estimates of σₙ (defined on a log scale).\nnugget: The term to add to the diagonals of the covariance matrix in case the matrix is not positive definite.\nnum_restarts = 50: Number of times to restart the optimiser. See opt_restart!.\nbootstrap_setup::Bootstrap_Setup: A Bootstrap_Setup struct for defining the bootstrapping grid.\n\nOutputs\n\ngp_setup: The fitted Gaussian process.\nμ: The mean vector for the joint Gaussian proces.\nL: The Cholesky factor for the joint Gaussian process.\n\n`\n\n\n\n\n\n","category":"function"},{"location":"ref.html#PDEs","page":"Manual","title":"PDEs","text":"","category":"section"},{"location":"ref.html","page":"Manual","title":"Manual","text":"boot_pde_solve\nerror_comp","category":"page"},{"location":"ref.html#EquationLearning.boot_pde_solve","page":"Manual","title":"EquationLearning.boot_pde_solve","text":"boot_pde_solve(bgp::BootResults, x_pde, t_pde, u_pde; prop_samples = 1.0, ICType = \"data\")\n\nSolve the PDEs corresponding to the bootstrap iterates in bgp obtained from bootstrap_gp. \n\nArguments\n\nbgp::BootResults: A BootResults struct containing the results from bootstrap_gp.\nx_pde: The spatial data to use for obtaining the initial condition.\nt_pde: The temporal data to use for obtaining the initial condition.\nu_pde: The density data to use for obtaining the initial condition.\n\nKeyword Arguments\n\nprop_samples = 1.0: The proportion of bootstrap samples to compute the corresponding PDE soluton to.\nICType = \"data\": The type of initial condition to use. Should be either \"data\" or \"gp\".\n\nOutputs\n\nsolns_all: The solutions to the PDEs over the mesh points at each time value.\n\nNote\n\nThe _pde subscript is used to indicate that these data need not be the same as the (x, t, u) used in bootstrap_gp, for example. For example, we may have 3 replicates of some data which we would easily use in bootstrap_gp, but for the PDE we would need to average these  together for obtaining the solutions.\n\n\n\n\n\nboot_pde_solve(bgp::BasisBootResults, x_pde, t_pde, u_pde; prop_samples = 1.0, ICType = \"data\")\n\nSolve the PDEs corresponding to the bootstrap iterates in bgp obtained from basis_bootstrap_gp. \n\nArguments\n\nbgp::BasisBootResults: A BasisBootResults struct containing the results from basis_bootstrap_gp.\nx_pde: The spatial data to use for obtaining the initial condition.\nt_pde: The temporal data to use for obtaining the initial condition.\nu_pde: The density data to use for obtaining the initial condition.\n\nKeyword Arguments\n\nprop_samples = 1.0: The proportion of bootstrap samples to compute teh corresponding PDE soluton to.\nICType = \"data\": The type of initial condition to use. Should be either \"data\" or \"gp\".\n\nOutputs\n\nsolns_all: The solutions to the PDEs over the mesh points at each time value.\n\nNote\n\nThe _pde subscript is used to indicate that these data need not be the same as the (x, t, u) used in bootstrap_gp, for example. For example, we may have 3 replicates of some data which we would easily use in bootstrap_gp, but for the PDE we would need to average these  together for obtaining the solutions.\n\n\n\n\n\n","category":"function"},{"location":"ref.html#EquationLearning.error_comp","page":"Manual","title":"EquationLearning.error_comp","text":"error_comp(bgp, solns_all, x, t, u; level = 0.05)\n\nComputes the error between solutions to a PDE compared to data (x, t, u) from the bootstrapping procedure. The error measure used is median(100 * (absolute errors) / max(eps(Float64), u)).\n\nArguments\n\nbgp: Bootstrapping results.\nsolns_all: PDE solutions.\nx: Spatial data.\nt: Temporal data.\nu: Density data.\n\nKeyword Arguments\n\nlevel = 0.05: Level for the confidence interval.\ncompute_mean = false: Whether to only report the mean.\n\nOutputs\n\nerr_CI: 100(1-level)% confidence interval for the error.\n\n\n\n\n\n","category":"function"},{"location":"ref.html#Plotting","page":"Manual","title":"Plotting","text":"","category":"section"},{"location":"ref.html","page":"Manual","title":"Manual","text":"density_values\ndensity_results\ncurve_values\ncurve_results\npde_values\npde_results\ndelay_product","category":"page"},{"location":"ref.html#EquationLearning.density_values","page":"Manual","title":"EquationLearning.density_values","text":"density_values(bgp::BootResults; <keyword arguments>)\n\nComputes the densities for the bootstrapping results in bgp.\n\nArguments\n\nbgp: A BootResults object which contains the results for the bootstrapping. \n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nfontsize = 23: Font size for the plots (to be used in plot_aes!).\ndelay_scales = nothing: Values that multiply the individual delay parameters.\ndiffusion_scales = nothing: Values that multiply the individual diffusion parameters. \nreaction_scales = nothing: Values that multiply the individual reaction parameters.\n\nOutputs\n\ntrv: Delay densities.\ndr: Diffusion densities. \nrr: Reaction densities. \ntt: Number of delay parameters.\nd: Number of diffusion parameters.\nr: Number of reaction parameters. \ndelayCIs: Confidence intervals for the delay parameters. \ndiffusionCIs: Confidence intervals for the diffusion parameters. \nreactionCIS: Confidence intervals for the reaction parameters.\n\n\n\n\n\ndensity_values(bgp::BasisBootResults; <keyword arguments>)\n\nComputes the densities for the bootstrapping results in bgp from a basis function approach.\n\nArguments\n\nbgp: A BasisBootResults object which contains the results for the bootstrapping. \n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nfontsize = 23: Font size for the plots (to be used in plot_aes!).\ndiffusion_scales = nothing: Values that multiply the individual diffusion parameters. \nreaction_scales = nothing: Values that multiply the individual reaction parameters.\n\nOutputs\n\ndr: Diffusion densities. \nrr: Reaction densities. \nd: Number of diffusion parameters.\nr: Number of reaction parameters. \ndelayCIs: Confidence intervals for the delay parameters. \ndiffusionCIs: Confidence intervals for the diffusion parameters. \nreactionCIS: Confidence intervals for the reaction parameters.\n\n\n\n\n\n","category":"function"},{"location":"ref.html#EquationLearning.density_results","page":"Manual","title":"EquationLearning.density_results","text":"density_results(bgp::BootResults; <keyword arguments>)\n\nPlots the densities for the bootstrapping results in bgp.\n\nArguments\n\nbgp: A BootResults object which contains the results for the bootstrapping. \n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nfontsize = 23: Font size for the plots (to be used in plot_aes!).\ndelay_scales = nothing: Values that multiply the individual delay parameters.\ndiffusion_scales = nothing: Values that multiply the individual diffusion parameters. \nreaction_scales = nothing: Values that multiply the individual reaction parameters.\ndiffusion_resolution = (800, 800): Resolution for the diffusion figure.\nreaction_resolution = (800, 800): Resolution for the reaction figure.\ndelay_resolution = (800, 800): Resolution for the delay fgure.\n\nOutputs\n\ndelayDensityFigure: A figure of plots containing a density plot for each delay parameter.\ndiffusionDensityFigure: A figure of plots containing a density plot for each diffusion parameter.\nreactionDensityFigure: A figure of plots containing a density plot for each reaction parameter.\n\n\n\n\n\ndensity_results(bgp::BasisBootResults; <keyword arguments>)\n\nPlots the densities for the bootstrapping results in bgp with the basis function approach.\n\nArguments\n\nbgp: A BasisBootResults object which contains the results for the bootstrapping. \n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nfontsize = 23: Font size for the plots (to be used in plot_aes!).\ndiffusion_scales = nothing: Values that multiply the individual diffusion parameters. \nreaction_scales = nothing: Values that multiply the individual reaction parameters.\ndiffusion_resolution = (800, 800): Resolution for the diffusion figure.\nreaction_resolution = (800, 800): Resolution for the reaction figure.\n\nOutputs\n\ndiffusionDensityFigure: A figure of plots containing a density plot for each diffusion parameter.\nreactionDensityFigure: A figure of plots containing a density plot for each reaction parameter.\n\n\n\n\n\n","category":"function"},{"location":"ref.html#EquationLearning.curve_values","page":"Manual","title":"EquationLearning.curve_values","text":"curve_values(bgp::BootResults; <keyword arguments>)\n\nComputes values for plotting the learned functional forms along with confidence intervals for the bootstrapping results in bgp.\n\nArguments\n\nbgp: A BootResults object which contains the results for the bootstrapping. \n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nx_scale = 1.0: Value used for scaling the spatial data (and all other length units, e.g. for diffusion).\nt_scale = 1.0: Value used for scaling the temporal data (and all other time units, e.g. for reaction).\n\nOutputs\n\nTu_vals: Ribbon features for the delay functions. \nDu_vals: Ribbon features for the diffusion functions.\nRu_vals: Ribbon features for the reaction functions.\nu_vals: The density values used for computing the functions. \nt_vals: The time values used for computing the functions.\n\n\n\n\n\ncurve_values(bgp::BasisBootResults; <keyword arguments>)\n\nComputes values for plotting the learned functional forms along with confidence intervals for the bootstrapping results in bgp from the basis function approach.\n\nArguments\n\nbgp: A BasisBootResults object which contains the results for the bootstrapping. \n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nx_scale = 1.0: Value used for scaling the spatial data (and all other length units, e.g. for diffusion).\nt_scale = 1.0: Value used for scaling the temporal data (and all other time units, e.g. for reaction).\n\nOutputs\n\nDu_vals: Ribbon features for the diffusion functions.\nRu_vals: Ribbon features for the reaction functions.\nu_vals: The density values used for computing the functions. \nt_vals: The time values used for computing the functions.\n\n\n\n\n\n","category":"function"},{"location":"ref.html#EquationLearning.curve_results","page":"Manual","title":"EquationLearning.curve_results","text":"curve_results(bgp::BootResults; <keyword arguments>)\n\nPlots the learned functional forms along with confidence intervals for the bootstrapping results in bgp.\n\nArguments\n\nbgp: A BootResults object which contains the results for the bootstrapping. \n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nfontsize = 23: Font size for the plots (to be used in plot_aes!).\nx_scale = 1.0: Value used for scaling the spatial data (and all other length units, e.g. for diffusion).\nt_scale = 1.0: Value used for scaling the temporal data (and all other time units, e.g. for reaction).\n\nOutputs\n\ndelayCurvePlots: A plot containing the learned functional form for the delay function, along with an uncertainty ribbon.\ndiffusionCurvePlots: A plot containing the learned functional form for the diffusion function, along with an uncertainty ribbon.\nreactionCurvePlots: A plot containing the learned functional form for the reaction function, along with an uncertainty ribbon.\n\n\n\n\n\ncurve_results(bgp::BasisBootResults; <keyword arguments>)\n\nPlots the learned functional forms along with confidence intervals for the bootstrapping results in bgp from the basis function approach.\n\nArguments\n\nbgp: A BasisBootResults object which contains the results for the bootstrapping. \n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nfontsize = 23: Font size for the plots (to be used in plot_aes!).\nx_scale = 1.0: Value used for scaling the spatial data (and all other length units, e.g. for diffusion).\nt_scale = 1.0: Value used for scaling the temporal data (and all other time units, e.g. for reaction).\n\nOutputs\n\ndiffusionCurvePlots: A plot containing the learned functional form for the diffusion function, along with an uncertainty ribbon.\nreactionCurvePlots: A plot containing the learned functional form for the reaction function, along with an uncertainty ribbon.\n\n\n\n\n\n","category":"function"},{"location":"ref.html#EquationLearning.pde_values","page":"Manual","title":"EquationLearning.pde_values","text":"function pde_values(solns_all, bgp::Union{BootResults, BasisBootResults}; level = 0.05)\n\nPlots the solutions to the PDEs corresponding to the bootstrap samples of bootstrap_gp using  the computed solutins in boot_pde_solve.\n\nArguments\n\nsolns_all: The solutions to the PDEs for each bootstrap iteration. \nbgp::Union{BootResults, BasisBootResults}: Bootstrapping results.\n\nKeyword Arguments\n\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \n\nOutputs\n\nsoln_vals_mean: Mean solution values. \nsoln_vals_lowers: Lower confidence interval for solution values.\nsoln_vals_upper: Upper confidence interval for solution values.\n\n\n\n\n\n","category":"function"},{"location":"ref.html#EquationLearning.pde_results","page":"Manual","title":"EquationLearning.pde_results","text":"pde_results(x_pde, t_pde u_pde, solns_all, bgp::Union{BootResults, BasisBootResults}; <keyword arguments>)\n\nPlots the solutions to the PDEs corresponding to the bootstrap samples of bootstrap_gp using  the computed solutins in boot_pde_solve.\n\nArguments\n\nx_pde: The spatial data to plot as points.\nt_pde: The temporal data to plot as points.\nu_pde: The density data to plot as points. \nsolns_all: The solutions to the PDEs for each bootstrap iteration. \nbgp::Union{BootResults, BasisBootResults}: A BootResults or BasisBootResults struct containing the results from bootstrap_gp or basis_bootstrap_gp, respectively.\n\nKeyword Arguments\n\ncolors = [:black, :blue, :red, :magenta, :green]: A list of colors for colouring the solutions at each time.\nlevel = 0.05: The significance level for computing the credible intervals for the parameter values. \nfontsize = 23: Font size for the plots (to be used in plot_aes!).\nx_scale = 1.0: Value used for scaling the spatial data (and all other length units, e.g. for diffusion).\nt_scale = 1.0: Value used for scaling the temporal data (and all other time units, e.g. for reaction).`\n\nOutputs\n\npdeSolutionPlots_BGP: The plot of the PDE solutions.\n\n\n\n\n\n","category":"function"},{"location":"ref.html#EquationLearning.delay_product","page":"Manual","title":"EquationLearning.delay_product","text":"delay_product(bgp, t; type = \"diffusion\", level = 0.05, x_scale = 1.0, t_scale = 1.0)\n\nComputes the curve T(t; α)D(u; β) (if type = \"diffusion\") or T(t; β)R(u; γ) (if type = \"reaction\") with uncertainty for the results in bgp, at the time t. The significance level is determined by level (0.05 default) and the spatial and temporal data are scaled by x_scale (1.0 default) and t_scale (1.0 default), respectively.\n\n\n\n\n\n","category":"function"},{"location":"ref.html#Data-Generation","page":"Manual","title":"Data Generation","text":"","category":"section"},{"location":"ref.html","page":"Manual","title":"Manual","text":"generate_data ","category":"page"},{"location":"ref.html#EquationLearning.generate_data","page":"Manual","title":"EquationLearning.generate_data","text":"generate_data(x₀, u₀, T, D, R, α, β, γ, δt, finalTime; <keyword arguments>)\n\nGenerate synthetic data from values (x₀, t₀) at t = 0 with exact mechanisms T, D, and R for delay, diffusion, and reaction, respectively. \n\nArguments\n\nx₀: The spatial mesh for points at t = 0.\nu₀: The density values at t = 0 corresponding to the points in x₀.\nT: A delay function of the form T(t, α, T_params).\nD: A diffusion function of the form D(u, β, D_params).\nR: A reaction function of the form R(u, γ, R_params).\nD′: The derivative of the diffusion function, given in the form D′(u, β, D_params).\nR′: The reaction function, given in the form R(u, γ, R_params).\nα: Exact values for the delay parameters.\nβ: Exact values for the diffusion parameters.\nγ: Exact values for the reaction parameters. \nδt: Times to save the solution to the differential equations at for generating the data.\nfinalTime: The time to solve the differential equations up to.\n\nKeyword Arguments\n\nN = 1000: The number of mesh points to use.\nLHS = [0.0, 1.0, 0.0]: Vector defining the left-hand boundary conditions for the PDE. See also the definitions of (a₀, b₀, c₀) in sysdegeneral!.\nRHS = [0.0, -1.0, 0.0]: Vector defining the right-hand boundary conditions for the PDE. See also the definitions of (a₁, b₁, c₁) in sysdegeneral!.\nalg = nothing: The algorithm to use for solving the differential equations.\nN_thin = 100: The number of points to take from the solution at each time.\nnum_restarts = 50: The number of times to restart the optimiser for fitting the Gaussian process to the data.\nD_params: Additional known parameters for the diffusion function.\nR_params: Additional known parameters for the reaction function.\nT_params: Additional known parameters for the delay function.\n\n\n\n\n\n","category":"function"},{"location":"ref.html#Model-Comparison","page":"Manual","title":"Model Comparison","text":"","category":"section"},{"location":"ref.html","page":"Manual","title":"Manual","text":"AIC \ncompare_AICs ","category":"page"},{"location":"ref.html#EquationLearning.AIC","page":"Manual","title":"EquationLearning.AIC","text":"AIC(bgp::Union{BootResults, BasisBootResults}; correct = true)\n\nComputes all the AIC values for the results in bgp. A small-sample size correction is used  if correct = true. The formulas used are given in Eq. 6 (uncorrected) or Eq. 17 (corrected) of Banks and Joyner (2017) [https://doi.org/10.1016/j.aml.2017.05.005].\n\n\n\n\n\n","category":"function"},{"location":"ref.html#EquationLearning.compare_AICs","page":"Manual","title":"EquationLearning.compare_AICs","text":"compare_AICs(AICs::Float64...)\n\nCompares the AIC values in AICs.... See also classify_Δᵢ and AIC.\n\n\n\n\n\ncompare_AICs(AICs::Vector{Float64}...)\n\nCompares many AICs by comparing entry-wise. The results are averaged. Assumes that each AIC is of equal length,  otherwise computes only up to the minimum length.\n\n\n\n\n\ncompare_AICs(x, t, u, models::Union{BootResults, BasisBootResults}...; correct = true)\n\nCompare several bootstrapped models using AIC.\n\n\n\n\n\n","category":"function"}]
}
